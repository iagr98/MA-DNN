{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bd2b1d",
   "metadata": {},
   "source": [
    "### 1.\n",
    "Importing data and splitting into test, validation and training data. (Only run one time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367a80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def fit_minmax(X):\n",
    "    \"\"\"Fit per-feature min-max on X (2D). Returns (mins, ranges) with safe ranges.\"\"\"\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    rng = maxs - mins\n",
    "    rng_safe = np.where(rng > 0, rng, 1.0)  # avoid division by zero (constant features)\n",
    "    return mins.astype(DTYPE), rng_safe.astype(DTYPE)\n",
    "\n",
    "def transform_minmax(X, mins, rng_safe):\n",
    "    return ((X - mins) / rng_safe).astype(DTYPE)\n",
    "\n",
    "def inverse_minmax(X_scaled, mins, rng_safe):\n",
    "    return (X_scaled * rng_safe + mins).astype(DTYPE)\n",
    "\n",
    "def split_dataframe_rows(df, train_frac, val_frac, test_frac, seed=42):\n",
    "    \"\"\"Split the *rows* of the original df into train/val/test by fraction.\"\"\"\n",
    "    assert abs((train_frac + val_frac + test_frac) - 1.0) < 1e-8, \"Fractions must sum to 1.\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = df.index.to_numpy()\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n = len(idx)\n",
    "    n_train = int(round(train_frac * n))\n",
    "    n_val = int(round(val_frac * n))\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx   = idx[n_train:n_train + n_val]\n",
    "    test_idx  = idx[n_train + n_val:]\n",
    "\n",
    "    return df.loc[train_idx], df.loc[val_idx], df.loc[test_idx]\n",
    "\n",
    "\n",
    "def expand_split(df_split):\n",
    "    \"\"\"\n",
    "    Expand a split of the original df into (X, Y) arrays by iterating each row,\n",
    "    parsing vector fields, masking NaNs per-row, and stacking all samples.\n",
    "    \"\"\"\n",
    "    inputs, outputs = [], []\n",
    "\n",
    "    for _, row in df_split.iterrows():\n",
    "        # ---- scalar inputs (with the same preprocessing as in your pipeline) ----\n",
    "        dV_ges   = float(row[\"dV_ges\"]) / 3.6 * 1e-6\n",
    "        eps_0    = float(row[\"eps_0\"])\n",
    "        phi_0    = float(row[\"phi_0\"])\n",
    "        h_dis_0  = float(row[\"h_dis_0\"])\n",
    "        h_c_0    = float(row[\"h_c_0\"])\n",
    "        rho_c    = float(row[\"rho_c\"])\n",
    "        rho_d    = float(row[\"rho_d\"])\n",
    "        eta_c    = float(row[\"eta_c\"])\n",
    "        eta_d    = float(row[\"etc_d\"])\n",
    "        sigma    = float(row[\"sigma\"])\n",
    "        T        = float(row[\"T\"])\n",
    "        r_s_star = float(row[\"r_S_star\"])\n",
    "        h_p_star = float(row[\"h_p_star\"])\n",
    "        D_A      = float(row[\"D_A\"])\n",
    "        L_A      = float(row[\"L_A\"])\n",
    "\n",
    "        # ---- vector fields (convert units like before) ----\n",
    "        DPZ_pos    = np.fromstring(str(row['DPZ_pos_ivgu']).strip(\"[]\"), sep=\",\") / 100.0     # m\n",
    "        DPZ_height = np.fromstring(str(row['DPZ_height_ivgu']).strip(\"[]\"), sep=\",\") / 1000.0 # m\n",
    "        DPZ_bot    = np.fromstring(str(row['DPZ_bot_ivgu']).strip(\"[]\"), sep=\",\") / 1000.0   # m\n",
    "\n",
    "        # ---- per-row NaN mask to keep only valid aligned entries ----\n",
    "        mask = ~(np.isnan(DPZ_pos) | np.isnan(DPZ_height) | np.isnan(DPZ_bot))\n",
    "        if not np.any(mask):\n",
    "            continue  # skip row if nothing valid\n",
    "\n",
    "        DPZ_pos_v    = DPZ_pos[mask]\n",
    "        DPZ_height_v = DPZ_height[mask]\n",
    "        DPZ_bot_v    = DPZ_bot[mask]\n",
    "\n",
    "        # ---- expand: one sample per DPZ position ----\n",
    "        const_feats = [dV_ges, eps_0, phi_0, h_dis_0, h_c_0, rho_c, rho_d,\n",
    "                       eta_c, eta_d, sigma, T, r_s_star, h_p_star, D_A, L_A]\n",
    "        for i in range(len(DPZ_pos_v)):\n",
    "            x_vec = const_feats + [DPZ_pos_v[i]]\n",
    "            y_vec = [DPZ_height_v[i], DPZ_bot_v[i]]\n",
    "            inputs.append(x_vec)\n",
    "            outputs.append(y_vec)\n",
    "\n",
    "    X = np.array(inputs, dtype=DTYPE)\n",
    "    Y = np.array(outputs, dtype=DTYPE)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53274779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row splits: train=297, val=64, test=63\n",
      "Expanded sample counts: train=7005, val=1536, test=1483\n",
      "Feature/Target dims: 16 2\n",
      "Torch tensors: torch.Size([7005, 16]) torch.Size([7005, 2]) torch.Size([1536, 16]) torch.Size([1536, 2]) torch.Size([1483, 16]) torch.Size([1483, 2])\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FRAC, VAL_FRAC, TEST_FRAC = 0.70, 0.15, 0.15\n",
    "SEED = 42\n",
    "DTYPE = np.float32\n",
    "CSV_PATH = os.path.join(\"Input\", \"df_dpz.csv\")\n",
    "\n",
    "# 1) Read original CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 2) Split by original rows (no expansion yet)\n",
    "train_df, val_df, test_df = split_dataframe_rows(df, TRAIN_FRAC, VAL_FRAC, TEST_FRAC, seed=SEED)\n",
    "print(f\"Row splits: train={len(train_df)}, val={len(val_df)}, test={len(test_df)}\")\n",
    "test_df.to_csv(\"df_te.csv\", index=False)\n",
    "\n",
    "# 3) Expand each split separately (no cross-split leakage)\n",
    "X_train, Y_train = expand_split(train_df)\n",
    "X_val,   Y_val   = expand_split(val_df)\n",
    "X_test,  Y_test  = expand_split(test_df)\n",
    "\n",
    "print(\"Expanded sample counts:\", f\"train={len(X_train)}, val={len(X_val)}, test={len(X_test)}\")\n",
    "print(\"Feature/Target dims:\", X_train.shape[1], Y_train.shape[1])\n",
    "\n",
    "# 4) Fit Minâ€“Max on TRAIN only; transform all splits\n",
    "x_mins, x_rng = fit_minmax(X_train)\n",
    "y_mins, y_rng = fit_minmax(Y_train)\n",
    "\n",
    "X_train_n = transform_minmax(X_train, x_mins, x_rng)\n",
    "X_val_n   = transform_minmax(X_val,   x_mins, x_rng)\n",
    "X_test_n  = transform_minmax(X_test,  x_mins, x_rng)\n",
    "\n",
    "Y_train_n = transform_minmax(Y_train, y_mins, y_rng)\n",
    "Y_val_n   = transform_minmax(Y_val,   y_mins, y_rng)\n",
    "Y_test_n  = transform_minmax(Y_test,  y_mins, y_rng)\n",
    "\n",
    "# 5) Convert to torch tensors (ready for DataLoaders)\n",
    "X_train_t = torch.from_numpy(X_train_n)\n",
    "Y_train_t = torch.from_numpy(Y_train_n)\n",
    "X_val_t   = torch.from_numpy(X_val_n)\n",
    "Y_val_t   = torch.from_numpy(Y_val_n)\n",
    "X_test_t  = torch.from_numpy(X_test_n)\n",
    "Y_test_t  = torch.from_numpy(Y_test_n)\n",
    "\n",
    "print(\"Torch tensors:\",\n",
    "      X_train_t.shape, Y_train_t.shape,\n",
    "      X_val_t.shape,   Y_val_t.shape,\n",
    "      X_test_t.shape,  Y_test_t.shape)\n",
    "\n",
    "# Save normalization params for inference-time inverse-transform\n",
    "np.savez(\n",
    "    \"minmax_params_dnn_6_(dpz).npz\",\n",
    "    x_mins=x_mins, x_rng=x_rng,\n",
    "    y_mins=y_mins, y_rng=y_rng\n",
    ")\n",
    "\n",
    "# Save splits as torch tensors\n",
    "data = {\n",
    "    \"X_train_t\": X_train_t,\n",
    "    \"Y_train_t\": Y_train_t,\n",
    "    \"X_val_t\":   X_val_t,\n",
    "    \"Y_val_t\":   Y_val_t,\n",
    "    \"X_test_t\":  X_test_t,\n",
    "    \"Y_test_t\":  Y_test_t,\n",
    "    \"X_train_n\": X_train_n,\n",
    "    \"Y_train_n\": Y_train_n,\n",
    "    \"X_val_n\":   X_val_n,\n",
    "    \"Y_val_n\":   Y_val_n,\n",
    "    \"X_test_n\":  X_test_n,\n",
    "    \"Y_test_n\":  Y_test_n,\n",
    "}\n",
    "\n",
    "# Save all in one file\n",
    "torch.save(data, 'datasets_dnn_6_(dpz).pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2e0bc",
   "metadata": {},
   "source": [
    "### 2.\n",
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a728c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iagr9\\AppData\\Local\\Temp\\ipykernel_188448\\2726911779.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(\"saved_models/dnn_5_(dpz)/datasets_dnn_5_(dpz).pt\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DTYPE = np.float32\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True  # faster on GPU\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loaded_data = torch.load(\"saved_models/dnn_5_(dpz)/datasets_dnn_5_(dpz).pt\")\n",
    "\n",
    "# Access tensors or arrays\n",
    "X_train_t = loaded_data[\"X_train_t\"]\n",
    "X_train_n = loaded_data[\"X_train_n\"]\n",
    "Y_train_t = loaded_data[\"Y_train_t\"]\n",
    "Y_train_n = loaded_data[\"Y_train_n\"]\n",
    "X_val_t = loaded_data[\"X_val_t\"]\n",
    "X_val_n = loaded_data[\"X_val_n\"]\n",
    "Y_val_t = loaded_data[\"Y_val_t\"]\n",
    "Y_val_n = loaded_data[\"Y_val_n\"]\n",
    "X_test_t = loaded_data[\"X_test_t\"]\n",
    "X_test_n = loaded_data[\"X_test_n\"]\n",
    "Y_test_t = loaded_data[\"Y_test_t\"]\n",
    "Y_test_n = loaded_data[\"Y_test_n\"]\n",
    "\n",
    "loaded_data_n = np.load(\"saved_models/dnn_5_(dpz)/minmax_params_dnn_5_(dpz).npz\")\n",
    "x_mins = loaded_data_n[\"x_mins\"]\n",
    "x_rng = loaded_data_n[\"x_rng\"]\n",
    "y_mins = loaded_data_n[\"y_mins\"]\n",
    "y_rng = loaded_data_n[\"y_rng\"]\n",
    "\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, out_dim, activation=\"silu\", dropout=0.0):\n",
    "        super().__init__()\n",
    "        acts = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"gelu\": nn.GELU,\n",
    "            \"silu\": nn.SiLU,\n",
    "            \"tanh\": nn.Tanh\n",
    "        }\n",
    "        if activation not in acts:\n",
    "            raise ValueError(f\"activation must be one of {list(acts.keys())}\")\n",
    "        Act = acts[activation]\n",
    "\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for i, h in enumerate(hidden_dims):\n",
    "            layers += [nn.Linear(prev, h), Act()]\n",
    "            if dropout and dropout > 0:\n",
    "                layers += [nn.Dropout(p=dropout)]\n",
    "            prev = h\n",
    "        # Linear output for regression\n",
    "        layers += [nn.Linear(prev, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        # Weight init (He for ReLU/SiLU/GELU, Xavier for Tanh)\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if activation in (\"relu\", \"silu\", \"gelu\"):\n",
    "                    nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                else:  # tanh\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(m.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "in_dim  = X_train_t.shape[1]\n",
    "out_dim = Y_train_t.shape[1]\n",
    "hidden  = [192, 128, 128]\n",
    "dropout = 0.0541333655155206\n",
    "activation = 'relu'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNN(in_dim, hidden, out_dim, activation=activation, dropout=dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58179d4",
   "metadata": {},
   "source": [
    "### 4.\n",
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65310536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_ds = TensorDataset(X_train_t, Y_train_t)\n",
    "val_ds   = TensorDataset(X_val_t,   Y_val_t)\n",
    "test_ds  = TensorDataset(X_test_t,  Y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "# val_loader   = DataLoader(val_ds,   batch_size=2048, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()  # targets are scaled; MSE is fine\n",
    "lr = 1e-3\n",
    "weight_decay = 3.8e-7\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db6e47c",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43372ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train MSE: 0.015990 | val MSE: 0.008660 | LR: 1.00e-03\n",
      "Epoch 002 | train MSE: 0.008733 | val MSE: 0.007624 | LR: 1.00e-03\n",
      "Epoch 003 | train MSE: 0.007433 | val MSE: 0.006094 | LR: 1.00e-03\n",
      "Epoch 004 | train MSE: 0.005911 | val MSE: 0.004424 | LR: 1.00e-03\n",
      "Epoch 005 | train MSE: 0.004814 | val MSE: 0.003903 | LR: 1.00e-03\n",
      "Epoch 006 | train MSE: 0.004309 | val MSE: 0.003516 | LR: 1.00e-03\n",
      "Epoch 007 | train MSE: 0.004027 | val MSE: 0.003334 | LR: 1.00e-03\n",
      "Epoch 008 | train MSE: 0.003775 | val MSE: 0.005159 | LR: 1.00e-03\n",
      "Epoch 009 | train MSE: 0.003575 | val MSE: 0.002658 | LR: 1.00e-03\n",
      "Epoch 010 | train MSE: 0.003301 | val MSE: 0.002748 | LR: 1.00e-03\n",
      "Epoch 011 | train MSE: 0.003128 | val MSE: 0.002618 | LR: 1.00e-03\n",
      "Epoch 012 | train MSE: 0.003014 | val MSE: 0.002566 | LR: 1.00e-03\n",
      "Epoch 013 | train MSE: 0.002976 | val MSE: 0.002624 | LR: 1.00e-03\n",
      "Epoch 014 | train MSE: 0.002897 | val MSE: 0.002392 | LR: 1.00e-03\n",
      "Epoch 015 | train MSE: 0.002570 | val MSE: 0.002152 | LR: 1.00e-03\n",
      "Epoch 016 | train MSE: 0.002699 | val MSE: 0.002935 | LR: 1.00e-03\n",
      "Epoch 017 | train MSE: 0.002578 | val MSE: 0.002426 | LR: 1.00e-03\n",
      "Epoch 018 | train MSE: 0.002420 | val MSE: 0.002333 | LR: 1.00e-03\n",
      "Epoch 019 | train MSE: 0.002297 | val MSE: 0.002261 | LR: 1.00e-03\n",
      "Epoch 020 | train MSE: 0.002286 | val MSE: 0.002085 | LR: 1.00e-03\n",
      "Epoch 021 | train MSE: 0.002149 | val MSE: 0.002494 | LR: 1.00e-03\n",
      "Epoch 022 | train MSE: 0.002256 | val MSE: 0.002297 | LR: 1.00e-03\n",
      "Epoch 023 | train MSE: 0.002153 | val MSE: 0.002664 | LR: 1.00e-03\n",
      "Epoch 024 | train MSE: 0.002141 | val MSE: 0.002287 | LR: 1.00e-03\n",
      "Epoch 025 | train MSE: 0.002039 | val MSE: 0.002057 | LR: 1.00e-03\n",
      "Epoch 026 | train MSE: 0.002170 | val MSE: 0.002650 | LR: 1.00e-03\n",
      "Epoch 027 | train MSE: 0.002045 | val MSE: 0.002021 | LR: 1.00e-03\n",
      "Epoch 028 | train MSE: 0.002011 | val MSE: 0.001996 | LR: 1.00e-03\n",
      "Epoch 029 | train MSE: 0.001914 | val MSE: 0.002321 | LR: 1.00e-03\n",
      "Epoch 030 | train MSE: 0.001874 | val MSE: 0.001812 | LR: 1.00e-03\n",
      "Epoch 031 | train MSE: 0.001869 | val MSE: 0.002008 | LR: 1.00e-03\n",
      "Epoch 032 | train MSE: 0.001826 | val MSE: 0.002604 | LR: 1.00e-03\n",
      "Epoch 033 | train MSE: 0.001799 | val MSE: 0.001991 | LR: 1.00e-03\n",
      "Epoch 034 | train MSE: 0.001811 | val MSE: 0.001815 | LR: 1.00e-03\n",
      "Epoch 035 | train MSE: 0.001791 | val MSE: 0.001956 | LR: 1.00e-03\n",
      "Epoch 036 | train MSE: 0.001742 | val MSE: 0.001992 | LR: 1.00e-03\n",
      "Epoch 037 | train MSE: 0.001768 | val MSE: 0.002521 | LR: 1.00e-03\n",
      "Epoch 038 | train MSE: 0.001691 | val MSE: 0.002354 | LR: 1.00e-03\n",
      "Epoch 039 | train MSE: 0.001880 | val MSE: 0.002256 | LR: 1.00e-03\n",
      "Epoch 040 | train MSE: 0.001734 | val MSE: 0.002188 | LR: 1.00e-03\n",
      "Epoch 041 | train MSE: 0.001656 | val MSE: 0.002039 | LR: 1.00e-03\n",
      "Epoch 042 | train MSE: 0.001543 | val MSE: 0.002173 | LR: 1.00e-03\n",
      "Epoch 043 | train MSE: 0.001670 | val MSE: 0.002292 | LR: 1.00e-03\n",
      "Epoch 044 | train MSE: 0.001616 | val MSE: 0.001849 | LR: 1.00e-03\n",
      "Epoch 045 | train MSE: 0.001539 | val MSE: 0.002074 | LR: 1.00e-03\n",
      "Epoch 046 | train MSE: 0.001542 | val MSE: 0.001964 | LR: 1.00e-03\n",
      "Epoch 047 | train MSE: 0.001666 | val MSE: 0.002686 | LR: 1.00e-03\n",
      "Epoch 048 | train MSE: 0.001599 | val MSE: 0.002062 | LR: 1.00e-03\n",
      "Epoch 049 | train MSE: 0.001652 | val MSE: 0.002345 | LR: 1.00e-03\n",
      "Epoch 050 | train MSE: 0.001594 | val MSE: 0.002081 | LR: 1.00e-03\n",
      "Epoch 051 | train MSE: 0.001437 | val MSE: 0.001702 | LR: 1.00e-03\n",
      "Epoch 052 | train MSE: 0.001502 | val MSE: 0.001848 | LR: 1.00e-03\n",
      "Epoch 053 | train MSE: 0.001631 | val MSE: 0.001917 | LR: 1.00e-03\n",
      "Epoch 054 | train MSE: 0.001640 | val MSE: 0.001692 | LR: 1.00e-03\n",
      "Epoch 055 | train MSE: 0.001524 | val MSE: 0.002090 | LR: 1.00e-03\n",
      "Epoch 056 | train MSE: 0.001420 | val MSE: 0.001803 | LR: 1.00e-03\n",
      "Epoch 057 | train MSE: 0.001445 | val MSE: 0.002079 | LR: 1.00e-03\n",
      "Epoch 058 | train MSE: 0.001603 | val MSE: 0.002404 | LR: 1.00e-03\n",
      "Epoch 059 | train MSE: 0.001445 | val MSE: 0.001877 | LR: 1.00e-03\n",
      "Epoch 060 | train MSE: 0.001508 | val MSE: 0.001838 | LR: 1.00e-03\n",
      "Epoch 061 | train MSE: 0.001434 | val MSE: 0.001804 | LR: 1.00e-03\n",
      "Epoch 062 | train MSE: 0.001450 | val MSE: 0.001851 | LR: 1.00e-03\n",
      "Epoch 063 | train MSE: 0.001445 | val MSE: 0.001845 | LR: 1.00e-03\n",
      "Epoch 064 | train MSE: 0.001332 | val MSE: 0.001860 | LR: 1.00e-03\n",
      "Epoch 065 | train MSE: 0.001407 | val MSE: 0.001598 | LR: 1.00e-03\n",
      "Epoch 066 | train MSE: 0.001428 | val MSE: 0.001810 | LR: 1.00e-03\n",
      "Epoch 067 | train MSE: 0.001388 | val MSE: 0.001793 | LR: 1.00e-03\n",
      "Epoch 068 | train MSE: 0.001385 | val MSE: 0.001813 | LR: 1.00e-03\n",
      "Epoch 069 | train MSE: 0.001515 | val MSE: 0.001724 | LR: 1.00e-03\n",
      "Epoch 070 | train MSE: 0.001372 | val MSE: 0.001742 | LR: 1.00e-03\n",
      "Epoch 071 | train MSE: 0.001263 | val MSE: 0.001564 | LR: 1.00e-03\n",
      "Epoch 072 | train MSE: 0.001350 | val MSE: 0.001741 | LR: 1.00e-03\n",
      "Epoch 073 | train MSE: 0.001408 | val MSE: 0.002104 | LR: 1.00e-03\n",
      "Epoch 074 | train MSE: 0.001347 | val MSE: 0.002025 | LR: 1.00e-03\n",
      "Epoch 075 | train MSE: 0.001332 | val MSE: 0.002099 | LR: 1.00e-03\n",
      "Epoch 076 | train MSE: 0.001348 | val MSE: 0.001842 | LR: 1.00e-03\n",
      "Epoch 077 | train MSE: 0.001284 | val MSE: 0.001766 | LR: 1.00e-03\n",
      "Epoch 078 | train MSE: 0.001434 | val MSE: 0.001601 | LR: 1.00e-03\n",
      "Epoch 079 | train MSE: 0.001330 | val MSE: 0.001629 | LR: 1.00e-03\n",
      "Epoch 080 | train MSE: 0.001403 | val MSE: 0.001727 | LR: 1.00e-03\n",
      "Epoch 081 | train MSE: 0.001416 | val MSE: 0.001566 | LR: 1.00e-03\n",
      "Epoch 082 | train MSE: 0.001330 | val MSE: 0.001708 | LR: 1.00e-03\n",
      "Epoch 083 | train MSE: 0.001358 | val MSE: 0.001744 | LR: 1.00e-03\n",
      "Epoch 084 | train MSE: 0.001331 | val MSE: 0.001604 | LR: 1.00e-03\n",
      "Epoch 085 | train MSE: 0.001308 | val MSE: 0.002059 | LR: 1.00e-03\n",
      "Epoch 086 | train MSE: 0.001272 | val MSE: 0.001738 | LR: 1.00e-03\n",
      "Epoch 087 | train MSE: 0.001324 | val MSE: 0.001619 | LR: 1.00e-03\n",
      "Epoch 088 | train MSE: 0.001366 | val MSE: 0.001622 | LR: 1.00e-03\n",
      "Epoch 089 | train MSE: 0.001244 | val MSE: 0.001670 | LR: 1.00e-03\n",
      "Epoch 090 | train MSE: 0.001259 | val MSE: 0.001795 | LR: 1.00e-03\n",
      "Epoch 091 | train MSE: 0.001308 | val MSE: 0.001866 | LR: 1.00e-03\n",
      "Epoch 092 | train MSE: 0.001333 | val MSE: 0.001786 | LR: 1.00e-03\n",
      "Epoch 093 | train MSE: 0.001333 | val MSE: 0.001717 | LR: 1.00e-03\n",
      "Epoch 094 | train MSE: 0.001323 | val MSE: 0.001574 | LR: 1.00e-03\n",
      "Epoch 095 | train MSE: 0.001239 | val MSE: 0.001499 | LR: 1.00e-03\n",
      "Epoch 096 | train MSE: 0.001254 | val MSE: 0.001589 | LR: 1.00e-03\n",
      "Epoch 097 | train MSE: 0.001241 | val MSE: 0.001526 | LR: 1.00e-03\n",
      "Epoch 098 | train MSE: 0.001245 | val MSE: 0.001517 | LR: 1.00e-03\n",
      "Epoch 099 | train MSE: 0.001238 | val MSE: 0.002099 | LR: 1.00e-03\n",
      "Epoch 100 | train MSE: 0.001219 | val MSE: 0.001386 | LR: 1.00e-03\n",
      "Epoch 101 | train MSE: 0.001597 | val MSE: 0.001913 | LR: 1.00e-03\n",
      "Epoch 102 | train MSE: 0.001306 | val MSE: 0.001830 | LR: 1.00e-03\n",
      "Epoch 103 | train MSE: 0.001239 | val MSE: 0.001867 | LR: 1.00e-03\n",
      "Epoch 104 | train MSE: 0.001260 | val MSE: 0.001569 | LR: 1.00e-03\n",
      "Epoch 105 | train MSE: 0.001322 | val MSE: 0.001581 | LR: 1.00e-03\n",
      "Epoch 106 | train MSE: 0.001312 | val MSE: 0.001719 | LR: 1.00e-03\n",
      "Epoch 107 | train MSE: 0.001193 | val MSE: 0.001750 | LR: 1.00e-03\n",
      "Epoch 108 | train MSE: 0.001318 | val MSE: 0.002007 | LR: 1.00e-03\n",
      "Epoch 109 | train MSE: 0.001185 | val MSE: 0.001751 | LR: 1.00e-03\n",
      "Epoch 110 | train MSE: 0.001155 | val MSE: 0.001479 | LR: 1.00e-03\n",
      "Epoch 111 | train MSE: 0.001321 | val MSE: 0.001833 | LR: 1.00e-03\n",
      "Epoch 112 | train MSE: 0.001237 | val MSE: 0.001583 | LR: 1.00e-03\n",
      "Epoch 113 | train MSE: 0.001292 | val MSE: 0.001681 | LR: 1.00e-03\n",
      "Epoch 114 | train MSE: 0.001200 | val MSE: 0.001954 | LR: 1.00e-03\n",
      "Epoch 115 | train MSE: 0.001200 | val MSE: 0.001945 | LR: 1.00e-03\n",
      "Epoch 116 | train MSE: 0.001145 | val MSE: 0.001586 | LR: 1.00e-03\n",
      "Epoch 117 | train MSE: 0.001149 | val MSE: 0.001728 | LR: 1.00e-03\n",
      "Epoch 118 | train MSE: 0.001231 | val MSE: 0.001586 | LR: 1.00e-03\n",
      "Epoch 119 | train MSE: 0.001101 | val MSE: 0.001629 | LR: 1.00e-03\n",
      "Epoch 120 | train MSE: 0.001274 | val MSE: 0.001766 | LR: 1.00e-03\n",
      "Epoch 121 | train MSE: 0.001268 | val MSE: 0.001998 | LR: 1.00e-03\n",
      "Epoch 122 | train MSE: 0.001170 | val MSE: 0.001596 | LR: 1.00e-03\n",
      "Epoch 123 | train MSE: 0.001293 | val MSE: 0.001605 | LR: 1.00e-03\n",
      "Epoch 124 | train MSE: 0.001257 | val MSE: 0.001557 | LR: 1.00e-03\n",
      "Epoch 125 | train MSE: 0.001252 | val MSE: 0.002030 | LR: 1.00e-03\n",
      "Epoch 126 | train MSE: 0.001263 | val MSE: 0.001839 | LR: 1.00e-03\n",
      "Epoch 127 | train MSE: 0.001154 | val MSE: 0.001651 | LR: 1.00e-03\n",
      "Epoch 128 | train MSE: 0.001186 | val MSE: 0.001837 | LR: 1.00e-03\n",
      "Epoch 129 | train MSE: 0.001130 | val MSE: 0.001686 | LR: 1.00e-03\n",
      "Epoch 130 | train MSE: 0.001166 | val MSE: 0.001537 | LR: 1.00e-03\n",
      "Early stopping at epoch 130. Best val MSE: 0.001386\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "PATIENCE = 30\n",
    "steps_per_epoch = max(1, len(train_loader))\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, epochs=EPOCHS, steps_per_epoch=steps_per_epoch)\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "losses_history = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    losses_history.append([train_loss, val_loss, lr])\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val - 1e-8:\n",
    "        best_val = val_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train MSE: {train_loss:.6f} | val MSE: {val_loss:.6f} | LR: {lr:.2e}\")\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch}. Best val MSE: {best_val:.6f}\")\n",
    "        break\n",
    "\n",
    "\n",
    "# Load best model\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3902af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val MSE: 0.001598\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best val MSE: {best_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfe81af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "losses_history = np.array(losses_history)\n",
    "plt.plot(losses_history[:,0], label='Train Loss')\n",
    "plt.plot(losses_history[:,1], label='Val Loss')\n",
    "plt.vlines(np.argmin(losses_history[:,1]), linestyles='--', ymin=0, ymax=max(losses_history[:,1]), label='min_L_val', color='gray')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe0c31",
   "metadata": {},
   "source": [
    "Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6428b386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.003289\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mse(loader):\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            mse += loss.item() * xb.size(0)\n",
    "    return mse / len(loader.dataset)\n",
    "\n",
    "test_mse = evaluate_mse(test_loader)\n",
    "print(f\"Test MSE: {test_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784fa630",
   "metadata": {},
   "source": [
    "See metrics in original units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6367a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE (original units) per target:     [0.00323499 0.00176938]\n",
      "Test MAPE (original units) per target:    [      inf 1.7150084] %\n",
      "Test SMAPE (original units) per target:   [12.378776  1.717652] %\n",
      "Test RMSE (original units) per target:    [0.0053824 0.0029653]\n",
      "Test MSE (original units) per target:     [2.8970197e-05 8.7930111e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iagr9\\AppData\\Local\\Temp\\ipykernel_190536\\2600268352.py:37: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = 100 * np.mean(np.abs((preds_u - trues_u) / trues_u), axis=0)\n"
     ]
    }
   ],
   "source": [
    "DTYPE = np.float32\n",
    "\n",
    "def fit_minmax(X):\n",
    "    \"\"\"Fit per-feature min-max on X (2D). Returns (mins, ranges) with safe ranges.\"\"\"\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    rng = maxs - mins\n",
    "    rng_safe = np.where(rng > 0, rng, 1.0)  # avoid division by zero (constant features)\n",
    "    return mins.astype(DTYPE), rng_safe.astype(DTYPE)\n",
    "\n",
    "def transform_minmax(X, mins, rng_safe):\n",
    "    return ((X - mins) / rng_safe).astype(DTYPE)\n",
    "\n",
    "def inverse_minmax(X_scaled, mins, rng_safe):\n",
    "    return (X_scaled * rng_safe + mins).astype(DTYPE)\n",
    "\n",
    "try:\n",
    "    mm = np.load(\"saved_models/dnn_5_(dpz)/minmax_params_dnn_5_(dpz).npz\")\n",
    "    y_mins, y_rng = mm[\"y_mins\"], mm[\"y_rng\"]\n",
    "\n",
    "    # Compute MAE/RMSE in original units\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            pred = model(xb).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            trues.append(yb.numpy())\n",
    "    preds = np.vstack(preds)\n",
    "    trues = np.vstack(trues)\n",
    "\n",
    "    preds_u = inverse_minmax(preds, y_mins, y_rng)\n",
    "    trues_u = inverse_minmax(trues, y_mins, y_rng)\n",
    "\n",
    "    mae = np.mean(np.abs(preds_u - trues_u), axis=0)\n",
    "    mape = 100 * np.mean(np.abs((preds_u - trues_u) / trues_u), axis=0)\n",
    "    epsilon = 1e-8\n",
    "    smape = 100 * np.mean(2 * np.abs(preds_u - trues_u) / (np.abs(preds_u) + np.abs(trues_u) + epsilon), axis=0)\n",
    "    rmse = np.sqrt(np.mean((preds_u - trues_u) ** 2, axis=0))\n",
    "    mse = np.mean((preds_u - trues_u) ** 2, axis=0)\n",
    "    print(\"Test MAE (original units) per target:    \", mae)\n",
    "    print(\"Test MAPE (original units) per target:   \", mape, '%')\n",
    "    print(\"Test SMAPE (original units) per target:  \", smape, '%')\n",
    "    print(\"Test RMSE (original units) per target:   \", rmse)\n",
    "    print(\"Test MSE (original units) per target:    \", mse)\n",
    "except FileNotFoundError:\n",
    "    print(\"minmax_params.npz not found; skipping metrics in original units.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8aeccd",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19158c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to dnn_5_dpz.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"dnn_5_dpz.pt\")\n",
    "print(\"Saved model to dnn_5_dpz.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e516b",
   "metadata": {},
   "source": [
    "### 5.\n",
    "See results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a165bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iagr9\\AppData\\Local\\Temp\\ipykernel_188448\\1699574727.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"saved_models/dnn_5_(dpz)/dnn_5_dpz.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions (10 rows, unnormalized/original units):\n",
      "[[ 0.04410256  0.09986238]\n",
      " [ 0.0345334   0.0997982 ]\n",
      " [ 0.02239954  0.10046262]\n",
      " [ 0.0119646   0.10033292]\n",
      " [ 0.00519205  0.10090209]\n",
      " [ 0.00256271  0.10103688]\n",
      " [ 0.00142619  0.10105322]\n",
      " [ 0.00051245  0.10109146]\n",
      " [-0.0001917   0.10107649]\n",
      " [-0.00078209  0.10110024]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# Load saved model if needed\n",
    "hidden  = [192, 128, 128]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "in_dim = 16\n",
    "out_dim = 2\n",
    "dropout = 0.0541333655155206\n",
    "model = DNN(in_dim, hidden, out_dim, activation=\"relu\", dropout=dropout).to(device)\n",
    "model.load_state_dict(torch.load(\"saved_models/dnn_5_(dpz)/dnn_5_dpz.pt\"))\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "\n",
    "dV_ges    = 280        # original units (as in CSV)\n",
    "eps_0     = 0.2\n",
    "phi_0     = 1278e-6\n",
    "h_dis_0   = 0.04\n",
    "h_c_0     = 0.1\n",
    "rho_c     = 998.19\n",
    "rho_d     = 819.72\n",
    "eta_c     = 102e-5\n",
    "eta_d     = 973e-5\n",
    "sigma     = 0.036\n",
    "T         = 20\n",
    "r_s_star  = 0.00975\n",
    "h_p_star  = 0.2498\n",
    "D_A       = 0.15\n",
    "L_A       = 0.56\n",
    "# x_array   = np.linspace(0.0, 0.32, 10)  # DPZ_pos\n",
    "x_array   = np.linspace(0.0, 0.56, 10)  # DPZ_pos\n",
    "\n",
    "# Apply the SAME transformations you used when building X in training:\n",
    "# dV_ges -> /3.6 * 1e-6 ; DPZ_pos was in meters AFTER dividing by 100 in the CSV pipeline.\n",
    "# Here, x_array is already in meters, so no extra /100.\n",
    "dV_ges_tr = dV_ges / 3.6 * 1e-6\n",
    "\n",
    "const_feats = np.array(\n",
    "    [dV_ges_tr, eps_0, phi_0, h_dis_0, h_c_0,\n",
    "     rho_c, rho_d, eta_c, eta_d, sigma, T, r_s_star, h_p_star, D_A, L_A],\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Stack 10 rows, each with the 13 constant features + the varying DPZ_pos\n",
    "X_real = np.hstack([\n",
    "    np.repeat(const_feats[None, :], repeats=len(x_array), axis=0),\n",
    "    x_array.reshape(-1, 1).astype(np.float32)\n",
    "])  # shape (10, 14)\n",
    "\n",
    "assert X_real.shape[1] == in_dim, f\"Expected {in_dim} features, got {X_real.shape[1]}.\"\n",
    "\n",
    "X_scaled = transform_minmax(X_real, x_mins, x_rng)\n",
    "X_t = torch.from_numpy(X_scaled).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_scaled = model(X_t).cpu().numpy()\n",
    "\n",
    "def transform_minmax(X, mins, rng):\n",
    "    rng_safe = np.where(rng > 0, rng, 1.0)\n",
    "    return (X - mins) / rng_safe\n",
    "\n",
    "def inverse_minmax(Ys, mins, rng):\n",
    "    return Ys * rng + mins\n",
    "\n",
    "Y_pred = inverse_minmax(Y_scaled, y_mins, y_rng)  \n",
    "\n",
    "print(\"Predictions (10 rows, unnormalized/original units):\")\n",
    "print(Y_pred)\n",
    "\n",
    "plt.plot(x_array, Y_pred[:, 1])\n",
    "plt.plot(x_array, Y_pred[:,0]+Y_pred[:,1], label='DPZ_top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e343893",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"utils/dataset_splits_minmax.npz\") as d:\n",
    "    X_train = d[\"X_train\"]\n",
    "    X_val = d[\"X_val\"]\n",
    "    X_test = d[\"X_test\"]\n",
    "    Y_train = d[\"Y_train\"]\n",
    "    Y_val = d[\"Y_val\"]\n",
    "    Y_test = d[\"Y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c98246",
   "metadata": {},
   "source": [
    "### 6.\n",
    "Make optuna study for determining optimal hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e8fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iagr9\\AppData\\Local\\Temp\\ipykernel_186176\\3619682479.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(DATA_TORCH_PATH)\n",
      "c:\\Users\\iagr9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iagr9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-08-26 09:13:14,250] A new study created in memory with name: dnn_optuna_t_20250826_091314\n",
      "Best trial: 0. Best value: 4.76242e-05:   0%|          | 0/60 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:13:41,299] Trial 0 finished with value: 4.762424578075297e-05 and parameters: {'n_layers': 2, 'width_l1': 64, 'width_l2': 192, 'activation': 'silu', 'dropout': 0.14561457009902096, 'lr': 0.0003278187653397617, 'weight_decay': 6.870101665590006e-08, 'batch_size': 512, 'optimizer': 'adamw', 'max_epochs': 181}. Best is trial 0 with value: 4.762424578075297e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 4.76242e-05:   2%|â–         | 1/60 [01:12<26:45, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:14:26,760] Trial 1 finished with value: 5.51596764732191e-05 and parameters: {'n_layers': 1, 'width_l1': 256, 'activation': 'gelu', 'dropout': 0.2475884550556351, 'lr': 1.216702881459345e-05, 'weight_decay': 0.0028570800750407216, 'batch_size': 128, 'optimizer': 'adam', 'max_epochs': 245}. Best is trial 0 with value: 4.762424578075297e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 4.76242e-05:   3%|â–Ž         | 2/60 [02:27<36:47, 38.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:15:41,831] Trial 2 finished with value: 1.9736960136166697e-05 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 192, 'width_l3': 192, 'width_l4': 64, 'activation': 'relu', 'dropout': 0.1554911608578311, 'lr': 6.390259853593123e-05, 'weight_decay': 0.00023858166771428845, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 175}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:   5%|â–Œ         | 3/60 [04:55<52:34, 55.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:18:09,580] Trial 3 finished with value: 5.028921422460068e-05 and parameters: {'n_layers': 4, 'width_l1': 512, 'width_l2': 128, 'width_l3': 192, 'width_l4': 384, 'activation': 'tanh', 'dropout': 0.4303652916281717, 'lr': 1.0404501336028154e-05, 'weight_decay': 1.160068983900714e-05, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 168}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:   8%|â–Š         | 5/60 [05:34<1:06:20, 72.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:18:48,635] Trial 4 finished with value: 7.190991891548038e-05 and parameters: {'n_layers': 3, 'width_l1': 96, 'width_l2': 384, 'width_l3': 128, 'activation': 'relu', 'dropout': 0.26788734203737924, 'lr': 1.673627134612419e-05, 'weight_decay': 0.0010275784161907387, 'batch_size': 512, 'optimizer': 'adam', 'max_epochs': 167}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:   8%|â–Š         | 5/60 [05:59<1:06:20, 72.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:19:13,735] Trial 5 finished with value: 3.857019752710281e-05 and parameters: {'n_layers': 1, 'width_l1': 256, 'activation': 'gelu', 'dropout': 0.3299920230170895, 'lr': 0.0010576902036995882, 'weight_decay': 2.14390170468164e-05, 'batch_size': 512, 'optimizer': 'adam', 'max_epochs': 137}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  10%|â–ˆ         | 6/60 [06:04<50:40, 56.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:19:18,301] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  13%|â–ˆâ–Ž        | 8/60 [06:09<24:39, 28.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:19:23,390] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  15%|â–ˆâ–Œ        | 9/60 [06:20<19:41, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:19:34,903] Trial 8 finished with value: 4.9213379194649555e-05 and parameters: {'n_layers': 2, 'width_l1': 128, 'width_l2': 64, 'activation': 'tanh', 'dropout': 0.43353615929005185, 'lr': 0.0018289742175371328, 'weight_decay': 1.1696458740181163e-05, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 137}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  15%|â–ˆâ–Œ        | 9/60 [07:19<19:41, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:20:34,156] Trial 9 finished with value: 3.350916525353872e-05 and parameters: {'n_layers': 2, 'width_l1': 512, 'width_l2': 128, 'activation': 'gelu', 'dropout': 0.265677315784074, 'lr': 0.00021838296130342758, 'weight_decay': 6.676969754945983e-05, 'batch_size': 128, 'optimizer': 'adam', 'max_epochs': 155}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  17%|â–ˆâ–‹        | 10/60 [07:43<28:41, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:20:58,043] Trial 10 finished with value: 2.7930381596282434e-05 and parameters: {'n_layers': 1, 'width_l1': 96, 'activation': 'silu', 'dropout': 0.13996694847297142, 'lr': 0.002319087217474401, 'weight_decay': 0.0002675355506980832, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 82}. Best is trial 2 with value: 1.9736960136166697e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  18%|â–ˆâ–Š        | 11/60 [07:48<25:34, 31.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:21:02,557] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  20%|â–ˆâ–ˆ        | 12/60 [09:31<18:21, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:22:45,849] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.9737e-05:  22%|â–ˆâ–ˆâ–       | 13/60 [10:11<37:26, 47.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:23:26,070] Trial 13 finished with value: 1.7260932584880113e-05 and parameters: {'n_layers': 2, 'width_l1': 192, 'width_l2': 128, 'activation': 'silu', 'dropout': 0.15965681879520743, 'lr': 0.0022564135127852, 'weight_decay': 0.005054088956519247, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 208}. Best is trial 13 with value: 1.7260932584880113e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 1.72609e-05:  25%|â–ˆâ–ˆâ–Œ       | 15/60 [10:25<26:37, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:23:39,690] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 1.72609e-05:  25%|â–ˆâ–ˆâ–Œ       | 15/60 [11:37<26:37, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:24:52,132] Trial 15 finished with value: 1.287065560973133e-05 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 512, 'width_l3': 192, 'width_l4': 64, 'activation': 'relu', 'dropout': 0.12204463202991442, 'lr': 0.00016867308274551797, 'weight_decay': 0.00013353799117876255, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 218}. Best is trial 15 with value: 1.287065560973133e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 1.28707e-05:  27%|â–ˆâ–ˆâ–‹       | 16/60 [12:17<34:32, 47.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:25:32,201] Trial 16 finished with value: 2.453679129151472e-05 and parameters: {'n_layers': 1, 'width_l1': 384, 'activation': 'silu', 'dropout': 0.11004776477043404, 'lr': 0.0022050847026703593, 'weight_decay': 0.000676792787080488, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 244}. Best is trial 15 with value: 1.287065560973133e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  28%|â–ˆâ–ˆâ–Š       | 17/60 [14:50<32:10, 44.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:28:03,767] Trial 17 finished with value: 1.0075210809645796e-05 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 512, 'width_l3': 384, 'width_l4': 64, 'activation': 'gelu', 'dropout': 0.03205343693328462, 'lr': 0.0005253675762663736, 'weight_decay': 1.1573583496499484e-06, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 240}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  30%|â–ˆâ–ˆâ–ˆ       | 18/60 [16:39<53:51, 76.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:29:53,709] Trial 18 finished with value: 1.093508012672828e-05 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 512, 'width_l3': 384, 'width_l4': 64, 'activation': 'gelu', 'dropout': 0.11063610036379316, 'lr': 0.0008616375744486008, 'weight_decay': 5.358955605552678e-07, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 221}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 20/60 [18:14<59:12, 88.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:31:28,481] Trial 19 finished with value: 1.1942624041694216e-05 and parameters: {'n_layers': 3, 'width_l1': 64, 'width_l2': 512, 'width_l3': 384, 'activation': 'gelu', 'dropout': 0.10078317500823947, 'lr': 0.00148432744590687, 'weight_decay': 1.4879364435731448e-06, 'batch_size': 256, 'optimizer': 'adamw', 'max_epochs': 228}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 20/60 [20:19<59:12, 88.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:33:33,686] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 21/60 [21:41<1:05:09, 100.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:34:55,329] Trial 21 finished with value: 1.6023761569764854e-05 and parameters: {'n_layers': 3, 'width_l1': 64, 'width_l2': 512, 'width_l3': 384, 'activation': 'gelu', 'dropout': 0.1846609416863117, 'lr': 0.0007868448810321892, 'weight_decay': 1.0620240927742705e-05, 'batch_size': 256, 'optimizer': 'adamw', 'max_epochs': 201}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 22/60 [22:59<59:38, 94.16s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:36:14,051] Trial 22 finished with value: 1.1180219265346144e-05 and parameters: {'n_layers': 3, 'width_l1': 512, 'width_l2': 512, 'width_l3': 384, 'activation': 'gelu', 'dropout': 0.11317700827399277, 'lr': 0.0028370208955534977, 'weight_decay': 3.532690363448715e-07, 'batch_size': 128, 'optimizer': 'adam', 'max_epochs': 243}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 24/60 [23:08<39:00, 65.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:36:22,388] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 24/60 [23:15<39:00, 65.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:36:30,158] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 26/60 [23:26<20:44, 36.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:36:40,575] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 26/60 [24:36<20:44, 36.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:37:51,075] Trial 26 finished with value: 1.1794285986373628e-05 and parameters: {'n_layers': 3, 'width_l1': 512, 'width_l2': 512, 'width_l3': 384, 'activation': 'gelu', 'dropout': 0.021933802875545166, 'lr': 0.002502144137409699, 'weight_decay': 1.8021225589544238e-06, 'batch_size': 128, 'optimizer': 'adam', 'max_epochs': 217}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 27/60 [26:01<25:59, 47.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:39:15,502] Trial 27 finished with value: 1.1420308093571899e-05 and parameters: {'n_layers': 4, 'width_l1': 384, 'width_l2': 512, 'width_l3': 384, 'width_l4': 512, 'activation': 'gelu', 'dropout': 0.11535015368006842, 'lr': 0.0016422882567663367, 'weight_decay': 5.522890269918851e-08, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 222}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 28/60 [26:56<31:12, 58.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:40:10,549] Trial 28 finished with value: 1.7589009019047808e-05 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 256, 'width_l3': 384, 'width_l4': 128, 'activation': 'gelu', 'dropout': 0.26182238754160464, 'lr': 0.0019233016310677491, 'weight_decay': 3.823486425101486e-06, 'batch_size': 128, 'optimizer': 'adam', 'max_epochs': 231}. Best is trial 17 with value: 1.0075210809645796e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 1.00752e-05:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 29/60 [29:25<29:32, 57.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:42:39,699] Trial 29 finished with value: 9.298050590208126e-06 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 384, 'width_l4': 192, 'activation': 'gelu', 'dropout': 0.05701754588446239, 'lr': 0.0008784326862261809, 'weight_decay': 1.5528418818105578e-07, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 231}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 30/60 [31:24<42:35, 85.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:44:38,545] Trial 30 finished with value: 1.2470361705633573e-05 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 96, 'width_l4': 192, 'activation': 'gelu', 'dropout': 0.09074245158983894, 'lr': 0.00025802594958282095, 'weight_decay': 1.170060329220176e-08, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 250}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 31/60 [33:29<45:58, 95.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:46:43,758] Trial 31 finished with value: 1.3015518457374734e-05 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 384, 'width_l4': 192, 'activation': 'gelu', 'dropout': 0.04603439201019565, 'lr': 0.0014712441559502614, 'weight_decay': 8.078272530569277e-06, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 183}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 33/60 [33:41<34:08, 75.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:46:55,897] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 33/60 [34:55<34:08, 75.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:48:09,548] Trial 33 finished with value: 9.96353634263869e-06 and parameters: {'n_layers': 3, 'width_l1': 256, 'width_l2': 384, 'width_l3': 384, 'activation': 'relu', 'dropout': 0.05612754923605755, 'lr': 0.00020134318123243722, 'weight_decay': 9.467578108507623e-08, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 197}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 34/60 [36:20<32:58, 76.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:49:34,590] Trial 34 finished with value: 1.0396801333930247e-05 and parameters: {'n_layers': 4, 'width_l1': 256, 'width_l2': 384, 'width_l3': 256, 'width_l4': 192, 'activation': 'relu', 'dropout': 0.04099252678293715, 'lr': 0.00014203319025435406, 'weight_decay': 1.68222376629249e-07, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 209}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 35/60 [37:20<32:37, 78.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:50:34,446] Trial 35 finished with value: 1.0980528221201288e-05 and parameters: {'n_layers': 3, 'width_l1': 256, 'width_l2': 384, 'width_l3': 256, 'activation': 'relu', 'dropout': 0.04532998345925067, 'lr': 0.00023916396345169708, 'weight_decay': 2.0483383013119237e-07, 'batch_size': 128, 'optimizer': 'adam', 'max_epochs': 181}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 36/60 [38:24<29:19, 73.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:51:38,509] Trial 36 finished with value: 1.1344659659092335e-05 and parameters: {'n_layers': 4, 'width_l1': 256, 'width_l2': 384, 'width_l3': 256, 'width_l4': 192, 'activation': 'relu', 'dropout': 0.05241986102505822, 'lr': 0.00016759833170205108, 'weight_decay': 1.9509404299730443e-08, 'batch_size': 128, 'optimizer': 'adamw', 'max_epochs': 221}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 38/60 [38:34<18:55, 51.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:51:48,644] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 39/60 [38:40<13:16, 37.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:51:54,669] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 39/60 [38:54<13:16, 37.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:52:08,830] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 41/60 [39:45<11:36, 36.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:52:59,232] Trial 40 finished with value: 1.011504658284442e-05 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 256, 'width_l4': 192, 'activation': 'relu', 'dropout': 0.03427953521133802, 'lr': 0.0007428347922522791, 'weight_decay': 2.2902155698443757e-07, 'batch_size': 512, 'optimizer': 'adam', 'max_epochs': 223}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 41/60 [40:44<11:36, 36.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:53:58,540] Trial 41 finished with value: 9.51059375135325e-06 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 256, 'width_l4': 192, 'activation': 'relu', 'dropout': 0.024990775491679953, 'lr': 0.000609354235866249, 'weight_decay': 5.702834393767984e-08, 'batch_size': 256, 'optimizer': 'adam', 'max_epochs': 196}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 42/60 [41:31<13:05, 43.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:54:45,463] Trial 42 finished with value: 1.0285297397179724e-05 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 256, 'width_l4': 192, 'activation': 'relu', 'dropout': 0.04076710614296966, 'lr': 0.0015561500735812729, 'weight_decay': 1.1862573044770239e-06, 'batch_size': 256, 'optimizer': 'adam', 'max_epochs': 238}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 43/60 [42:40<12:41, 44.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:55:54,495] Trial 43 finished with value: 1.1855059483423247e-05 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 384, 'width_l3': 256, 'width_l4': 192, 'activation': 'relu', 'dropout': 0.012732642078103514, 'lr': 0.0001401318071168419, 'weight_decay': 1.283777858223526e-08, 'batch_size': 256, 'optimizer': 'adam', 'max_epochs': 134}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 44/60 [42:46<13:47, 51.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:56:01,121] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 46/60 [42:53<06:41, 28.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:56:07,647] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 46/60 [43:51<06:41, 28.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:57:05,852] Trial 46 finished with value: 9.354912871610091e-06 and parameters: {'n_layers': 3, 'width_l1': 192, 'width_l2': 384, 'width_l3': 128, 'activation': 'relu', 'dropout': 0.06079190703270015, 'lr': 0.001251797386433658, 'weight_decay': 5.83917202401797e-08, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 164}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 47/60 [44:46<08:17, 38.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:58:00,896] Trial 47 finished with value: 1.0986458699827987e-05 and parameters: {'n_layers': 3, 'width_l1': 128, 'width_l2': 64, 'width_l3': 128, 'activation': 'relu', 'dropout': 0.010005591880578653, 'lr': 0.00038454306583606077, 'weight_decay': 1.0073364481123236e-08, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 124}. Best is trial 29 with value: 9.298050590208126e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49/60 [45:06<06:30, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:58:20,625] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 9.29805e-06:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 49/60 [46:00<06:30, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:59:15,165] Trial 49 finished with value: 8.455700642192218e-06 and parameters: {'n_layers': 3, 'width_l1': 192, 'width_l2': 128, 'width_l3': 128, 'activation': 'relu', 'dropout': 0.0541333655155206, 'lr': 0.0010982392899715648, 'weight_decay': 3.8401620565224376e-07, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 157}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 50/60 [46:32<06:56, 41.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 09:59:46,930] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 51/60 [47:19<05:47, 38.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:00:34,032] Trial 51 finished with value: 1.182658237060726e-05 and parameters: {'n_layers': 3, 'width_l1': 256, 'width_l2': 128, 'width_l3': 128, 'activation': 'relu', 'dropout': 0.2360685578101602, 'lr': 0.0012088585492342283, 'weight_decay': 2.1073002886161253e-06, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 121}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 53/60 [47:33<03:46, 32.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:00:47,568] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 53/60 [48:54<03:46, 32.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:02:09,079] Trial 53 finished with value: 9.904311127684196e-06 and parameters: {'n_layers': 4, 'width_l1': 384, 'width_l2': 192, 'width_l3': 512, 'width_l4': 384, 'activation': 'relu', 'dropout': 0.17509473718222185, 'lr': 0.0006065718969652103, 'weight_decay': 7.082461343776925e-08, 'batch_size': 256, 'optimizer': 'adam', 'max_epochs': 176}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 54/60 [51:01<04:44, 47.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:04:16,192] Trial 54 finished with value: 8.985193010365341e-06 and parameters: {'n_layers': 4, 'width_l1': 192, 'width_l2': 192, 'width_l3': 512, 'width_l4': 384, 'activation': 'relu', 'dropout': 0.010708274533404873, 'lr': 0.0014146191688121604, 'weight_decay': 5.429881872822156e-07, 'batch_size': 64, 'optimizer': 'adamw', 'max_epochs': 108}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 55/60 [52:34<05:59, 71.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:05:48,450] Trial 55 finished with value: 8.851573866763829e-06 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 192, 'width_l3': 512, 'width_l4': 384, 'activation': 'relu', 'dropout': 0.0031888406694455277, 'lr': 0.0029225247629986973, 'weight_decay': 1.6390240411552319e-06, 'batch_size': 64, 'optimizer': 'adamw', 'max_epochs': 126}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 56/60 [53:37<05:11, 77.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:06:51,200] Trial 56 finished with value: 1.0003839425583768e-05 and parameters: {'n_layers': 3, 'width_l1': 192, 'width_l2': 192, 'width_l3': 512, 'activation': 'relu', 'dropout': 0.04259311597397668, 'lr': 0.001755117254833133, 'weight_decay': 1.4754231780926452e-06, 'batch_size': 64, 'optimizer': 'adamw', 'max_epochs': 82}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 57/60 [54:41<03:40, 73.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:07:56,021] Trial 57 finished with value: 1.2406592986735632e-05 and parameters: {'n_layers': 4, 'width_l1': 64, 'width_l2': 192, 'width_l3': 512, 'width_l4': 384, 'activation': 'relu', 'dropout': 0.039057839030891904, 'lr': 0.0022908455915055348, 'weight_decay': 7.412929125974802e-07, 'batch_size': 64, 'optimizer': 'adamw', 'max_epochs': 128}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 59/60 [55:48<01:09, 69.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:09:03,084] Trial 58 finished with value: 1.1078594828480467e-05 and parameters: {'n_layers': 4, 'width_l1': 384, 'width_l2': 192, 'width_l3': 512, 'width_l4': 384, 'activation': 'relu', 'dropout': 0.04378405886498059, 'lr': 0.0007031743574344268, 'weight_decay': 1.442714483826226e-05, 'batch_size': 512, 'optimizer': 'adamw', 'max_epochs': 125}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 59/60 [56:54<01:09, 69.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-26 10:10:08,718] Trial 59 finished with value: 1.0756883445613616e-05 and parameters: {'n_layers': 4, 'width_l1': 96, 'width_l2': 192, 'width_l3': 512, 'width_l4': 384, 'activation': 'relu', 'dropout': 0.0045164335099609765, 'lr': 0.0023789356208520295, 'weight_decay': 4.1481852258382536e-08, 'batch_size': 64, 'optimizer': 'adam', 'max_epochs': 168}. Best is trial 49 with value: 8.455700642192218e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 8.4557e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [56:55<00:00, 56.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Study statistics:\n",
      "  Completed trials: 60\n",
      "  Pruned trials: 18\n",
      "  Successful trials: 42\n",
      "\n",
      "Best trial:\n",
      "  Value (Val MSE, original scale): 0.000008\n",
      "  Params:\n",
      "    n_layers: 3\n",
      "    width_l1: 192\n",
      "    width_l2: 128\n",
      "    width_l3: 128\n",
      "    activation: relu\n",
      "    dropout: 0.0541333655155206\n",
      "    lr: 0.0010982392899715648\n",
      "    weight_decay: 3.8401620565224376e-07\n",
      "    batch_size: 64\n",
      "    optimizer: adam\n",
      "    max_epochs: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iagr9\\AppData\\Local\\Temp\\ipykernel_186176\\3619682479.py:264: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(state_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test MSE (original scale): 0.000020\n"
     ]
    }
   ],
   "source": [
    "# tune_dnn_optuna.py\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "# --------------------\n",
    "# Config\n",
    "# --------------------\n",
    "DATA_BUNDLE_DIR = \"saved_models/dnn_6_(dpz)\"\n",
    "DATA_TORCH_PATH = os.path.join(DATA_BUNDLE_DIR, \"datasets_dnn_6_(dpz).pt\")\n",
    "MM_PARAMS_NPZ   = os.path.join(DATA_BUNDLE_DIR, \"minmax_params_dnn_6_(dpz).npz\")\n",
    "RESULTS_DIR     = os.path.join(DATA_BUNDLE_DIR, \"optuna_runs\")\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True  # faster on GPU\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Choose which split variant to use: \"t\" or \"n\"\n",
    "SPLIT_VARIANT = \"t\"  # change to \"n\" if you want *_n\n",
    "\n",
    "# --------------------\n",
    "# Load data\n",
    "# --------------------\n",
    "if not os.path.exists(DATA_TORCH_PATH):\n",
    "    raise FileNotFoundError(f\"Could not find {DATA_TORCH_PATH}\")\n",
    "\n",
    "loaded_data = torch.load(DATA_TORCH_PATH)\n",
    "\n",
    "X_train = loaded_data[f\"X_train_{SPLIT_VARIANT}\"].float()\n",
    "Y_train = loaded_data[f\"Y_train_{SPLIT_VARIANT}\"].float()\n",
    "X_val   = loaded_data[f\"X_val_{SPLIT_VARIANT}\"].float()\n",
    "Y_val   = loaded_data[f\"Y_val_{SPLIT_VARIANT}\"].float()\n",
    "X_test  = loaded_data[f\"X_test_{SPLIT_VARIANT}\"].float()\n",
    "Y_test  = loaded_data[f\"Y_test_{SPLIT_VARIANT}\"].float()\n",
    "\n",
    "mm = np.load(MM_PARAMS_NPZ)\n",
    "y_mins = torch.tensor(mm[\"y_mins\"], dtype=torch.float32)\n",
    "y_rng  = torch.tensor(mm[\"y_rng\"],  dtype=torch.float32)\n",
    "\n",
    "in_dim  = X_train.shape[1]\n",
    "out_dim = Y_train.shape[1]\n",
    "\n",
    "# --------------------\n",
    "# Model definition (copied from your DNN with same init)\n",
    "# --------------------\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, out_dim, activation=\"silu\", dropout=0.0):\n",
    "        super().__init__()\n",
    "        acts = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"gelu\": nn.GELU,\n",
    "            \"silu\": nn.SiLU,\n",
    "            \"tanh\": nn.Tanh\n",
    "        }\n",
    "        if activation not in acts:\n",
    "            raise ValueError(f\"activation must be one of {list(acts.keys())}\")\n",
    "        Act = acts[activation]\n",
    "\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(prev, h), Act()]\n",
    "            if dropout and dropout > 0:\n",
    "                layers += [nn.Dropout(p=dropout)]\n",
    "            prev = h\n",
    "        layers += [nn.Linear(prev, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if activation in (\"relu\", \"silu\", \"gelu\"):\n",
    "                    nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                else:\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(m.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --------------------\n",
    "# Helpers\n",
    "# --------------------\n",
    "def denorm_y(y_norm: torch.Tensor) -> torch.Tensor:\n",
    "    # y = y_norm * y_rng + y_mins (broadcast over batch)\n",
    "    return y_norm * y_rng.to(y_norm.device) + y_mins.to(y_norm.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def mse_original_scale(model: nn.Module, loader: DataLoader, device=DEVICE) -> float:\n",
    "    model.eval()\n",
    "    se_sum, n_obs = 0.0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        pred = model(xb)\n",
    "        pred_den = denorm_y(pred)\n",
    "        y_den    = denorm_y(yb)\n",
    "        se_sum += torch.sum((pred_den - y_den) ** 2).item()\n",
    "        n_obs  += yb.numel()\n",
    "    mse = se_sum / n_obs\n",
    "    return float(mse)\n",
    "\n",
    "def make_hidden_dims(trial: optuna.Trial) -> list:\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
    "    dims = []\n",
    "    for i in range(n_layers):\n",
    "        dims.append(trial.suggest_categorical(f\"width_l{i+1}\", [64, 96, 128, 192, 256, 384, 512]))\n",
    "    return dims\n",
    "\n",
    "def make_optimizer(opt_name: str, params, lr: float, wd: float):\n",
    "    if opt_name == \"adam\":\n",
    "        return torch.optim.Adam(params, lr=lr, weight_decay=wd)\n",
    "    elif opt_name == \"adamw\":\n",
    "        return torch.optim.AdamW(params, lr=lr, weight_decay=wd)\n",
    "    else:\n",
    "        raise ValueError(opt_name)\n",
    "\n",
    "# --------------------\n",
    "# Objective\n",
    "# --------------------\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Search space\n",
    "    hidden_dims = make_hidden_dims(trial)\n",
    "    activation  = trial.suggest_categorical(\"activation\", [\"relu\", \"gelu\", \"silu\", \"tanh\"])\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-5, 3e-3, log=True)\n",
    "    weight_decay= trial.suggest_float(\"weight_decay\", 1e-8, 1e-2, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "    optimizer_n = trial.suggest_categorical(\"optimizer\", [\"adam\", \"adamw\"])\n",
    "    max_epochs  = trial.suggest_int(\"max_epochs\", 80, 250)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val,   Y_val),   batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    # Model / opt / loss\n",
    "    model = DNN(in_dim, hidden_dims, out_dim, activation=activation, dropout=dropout).to(DEVICE)\n",
    "    opt   = make_optimizer(optimizer_n, model.parameters(), lr, weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # OneCycleLR (optional): only if epochs >= 50\n",
    "    use_scheduler = max_epochs >= 50\n",
    "    if use_scheduler:\n",
    "        # steps_per_epoch = max(1, len(train_loader))\n",
    "        # scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=lr, epochs=max_epochs, steps_per_epoch=steps_per_epoch)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.1, patience=30)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # Early stopping + pruning\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    patience = 30\n",
    "    patience_left = patience\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "\n",
    "        # Validation metric (original scale MSE)\n",
    "        val_mse = mse_original_scale(model, val_loader, device=DEVICE)\n",
    "        if scheduler:\n",
    "            scheduler.step(val_mse)\n",
    "\n",
    "        # Report to Optuna and check pruning\n",
    "        trial.report(val_mse, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        # Early stopping tracking\n",
    "        if val_mse < best_val - 1e-6:\n",
    "            best_val = val_mse\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_left = patience\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "            if patience_left <= 0:\n",
    "                break\n",
    "\n",
    "    # Optionally save the trial's best model\n",
    "    trial_dir = os.path.join(RESULTS_DIR, f\"trial_{trial.number:04d}\")\n",
    "    os.makedirs(trial_dir, exist_ok=True)\n",
    "    with open(os.path.join(trial_dir, \"params.json\"), \"w\") as f:\n",
    "        json.dump(trial.params, f, indent=2)\n",
    "    if best_state is not None:\n",
    "        torch.save(best_state, os.path.join(trial_dir, \"best_state.pt\"))\n",
    "\n",
    "    return best_val\n",
    "\n",
    "# --------------------\n",
    "# Run Study\n",
    "# --------------------\n",
    "def main():\n",
    "    study_name = f\"dnn_optuna_{SPLIT_VARIANT}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    storage = None  # e.g., \"sqlite:///optuna_dnn.db\" if you want persistence\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"minimize\",\n",
    "        storage=storage,\n",
    "        load_if_exists=False,\n",
    "        pruner=MedianPruner(n_warmup_steps=15),\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED, n_startup_trials=15, multivariate=True, group=True),\n",
    "    )\n",
    "\n",
    "    # You can adjust n_trials as you like\n",
    "    study.optimize(objective, n_trials=60, show_progress_bar=True, gc_after_trial=True)\n",
    "\n",
    "    print(\"\\nStudy statistics:\")\n",
    "    print(f\"  Completed trials: {len(study.trials)}\")\n",
    "    pruned_trials = [t for t in study.trials if t.state == TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]\n",
    "    print(f\"  Pruned trials: {len(pruned_trials)}\")\n",
    "    print(f\"  Successful trials: {len(complete_trials)}\")\n",
    "\n",
    "    print(\"\\nBest trial:\")\n",
    "    best = study.best_trial\n",
    "    print(f\"  Value (Val MSE, original scale): {best.value:.6f}\")\n",
    "    print(\"  Params:\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    # Save best params + optionally evaluate on test set using saved state\n",
    "    best_dir = os.path.join(RESULTS_DIR, \"best\")\n",
    "    os.makedirs(best_dir, exist_ok=True)\n",
    "    with open(os.path.join(best_dir, \"best_params.json\"), \"w\") as f:\n",
    "        json.dump(best.params, f, indent=2)\n",
    "\n",
    "    # Rebuild best model and evaluate on test\n",
    "    hidden_dims = [best.params[f\"width_l{i+1}\"] for i in range(best.params[\"n_layers\"])]\n",
    "    model = DNN(in_dim, hidden_dims, out_dim,\n",
    "                activation=best.params[\"activation\"],\n",
    "                dropout=best.params[\"dropout\"]).to(DEVICE)\n",
    "\n",
    "    # Load the saved state from the best trial directory if present; otherwise use current weights\n",
    "    best_trial_dir = os.path.join(RESULTS_DIR, f\"trial_{best.number:04d}\")\n",
    "    state_path = os.path.join(best_trial_dir, \"best_state.pt\")\n",
    "    if os.path.exists(state_path):\n",
    "        model.load_state_dict(torch.load(state_path, map_location=DEVICE))\n",
    "\n",
    "    test_loader = DataLoader(TensorDataset(X_test, Y_test), batch_size=4096, shuffle=False)\n",
    "    test_mse = mse_original_scale(model, test_loader, device=DEVICE)\n",
    "    print(f\"\\nTest MSE (original scale): {test_mse:.6f}\")\n",
    "    with open(os.path.join(best_dir, \"best_summary.json\"), \"w\") as f:\n",
    "        json.dump({\"val_mse\": best.value, \"test_mse\": test_mse, \"trial_number\": best.number}, f, indent=2)\n",
    "\n",
    "    # Save final best model weights\n",
    "    torch.save(model.state_dict(), os.path.join(best_dir, \"best_model_state.pt\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
