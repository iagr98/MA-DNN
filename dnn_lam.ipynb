{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afbd7f7",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Import data, split, normalize and save. (Only run once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f56578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def fit_minmax(X):\n",
    "    \"\"\"Fit per-feature min-max on X (2D). Returns (mins, ranges) with safe ranges.\"\"\"\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    rng = maxs - mins\n",
    "    rng_safe = np.where(rng > 0, rng, 1.0)  # avoid division by zero (constant features)\n",
    "    return mins.astype(DTYPE), rng_safe.astype(DTYPE)\n",
    "\n",
    "def transform_minmax(X, mins, rng_safe):\n",
    "    return ((X - mins) / rng_safe).astype(DTYPE)\n",
    "\n",
    "def inverse_minmax(X_scaled, mins, rng_safe):\n",
    "    return (X_scaled * rng_safe + mins).astype(DTYPE)\n",
    "\n",
    "def split_dataframe_rows(df, train_frac, val_frac, test_frac, seed=42):\n",
    "    \"\"\"Split the *rows* of the original df into train/val/test by fraction.\"\"\"\n",
    "    assert abs((train_frac + val_frac + test_frac) - 1.0) < 1e-8, \"Fractions must sum to 1.\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = df.index.to_numpy()\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n = len(idx)\n",
    "    n_train = int(round(train_frac * n))\n",
    "    n_val = int(round(val_frac * n))\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx   = idx[n_train:n_train + n_val]\n",
    "    test_idx  = idx[n_train + n_val:]\n",
    "\n",
    "    return df.loc[train_idx], df.loc[val_idx], df.loc[test_idx]\n",
    "\n",
    "\n",
    "def create_inp_out(df_split):\n",
    "    \"\"\"\n",
    "    Creates inputs X and outputs Y of given df already splitted\n",
    "    \"\"\"\n",
    "    inputs, outputs = [], []\n",
    "\n",
    "    for _, row in df_split.iterrows():\n",
    "        # ---- scalar inputs (with the same preprocessing as in your pipeline) ----\n",
    "        dV_ges   = float(row[\"dV_ges\"]) / 3.6 * 1e-6\n",
    "        eps_0    = float(row[\"eps_0\"])\n",
    "        phi_0    = float(row[\"phi_0\"])\n",
    "        h_dis_0  = float(row[\"h_dis_0\"])\n",
    "        h_c_0    = float(row[\"h_c_0\"])\n",
    "        rho_c    = float(row[\"rho_c\"])\n",
    "        rho_d    = float(row[\"rho_d\"])\n",
    "        eta_c    = float(row[\"eta_c\"])\n",
    "        eta_d    = float(row[\"etc_d\"])\n",
    "        sigma    = float(row[\"sigma\"])\n",
    "        T        = float(row[\"T\"])\n",
    "        r_s_star = float(row[\"r_S_star\"])\n",
    "        h_p_star = float(row[\"h_p_star\"])\n",
    "        D_A      = float(row[\"D_A\"])\n",
    "        L_A      = float(row[\"L_A\"])\n",
    "        lam      = float(row[\"lambda\"])\n",
    "\n",
    "        # ---- expand: one sample per DPZ position ----\n",
    "        inputs.append([dV_ges, eps_0, phi_0, h_dis_0, h_c_0, rho_c, rho_d,\n",
    "                       eta_c, eta_d, sigma, T, r_s_star, h_p_star, D_A, L_A])\n",
    "        outputs.append(lam)\n",
    "\n",
    "    X = np.array(inputs, dtype=DTYPE)\n",
    "    Y = np.array(outputs, dtype=DTYPE)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c62fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row splits: train=276, val=59, test=60\n",
      "Sample counts: train=276, val=59, test=60\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m X_test,  Y_test  \u001b[38;5;241m=\u001b[39m create_inp_out(test_df)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample counts:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature/Target dims. for training:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[43mY_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 4) Fit Min–Max on TRAIN only; transform all splits\u001b[39;00m\n\u001b[0;32m     23\u001b[0m x_mins, x_rng \u001b[38;5;241m=\u001b[39m fit_minmax(X_train)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "TRAIN_FRAC, VAL_FRAC, TEST_FRAC = 0.70, 0.15, 0.15\n",
    "SEED = 42\n",
    "DTYPE = np.float32\n",
    "CSV_PATH = os.path.join(\"Input\", \"df_lam.csv\")\n",
    "\n",
    "# 1) Read original CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 2) Split by original rows\n",
    "train_df, val_df, test_df = split_dataframe_rows(df, TRAIN_FRAC, VAL_FRAC, TEST_FRAC, seed=SEED)\n",
    "print(f\"Row splits: train={len(train_df)}, val={len(val_df)}, test={len(test_df)}\")\n",
    "test_df.to_csv(\"df_lam_te.csv\", index=False)\n",
    "\n",
    "# 3) Expand each split separately (no cross-split leakage)\n",
    "X_train, Y_train = create_inp_out(train_df)\n",
    "X_val,   Y_val   = create_inp_out(val_df)\n",
    "X_test,  Y_test  = create_inp_out(test_df)\n",
    "\n",
    "print(\"Sample counts:\", f\"train={len(X_train)}, val={len(X_val)}, test={len(X_test)}\")\n",
    "print(\"Feature/Target dims. for training:\", X_train.shape[1], Y_train.shape[1])\n",
    "\n",
    "# 4) Fit Min–Max on TRAIN only; transform all splits\n",
    "x_mins, x_rng = fit_minmax(X_train)\n",
    "y_mins, y_rng = fit_minmax(Y_train)\n",
    "\n",
    "X_train_n = transform_minmax(X_train, x_mins, x_rng)\n",
    "X_val_n   = transform_minmax(X_val,   x_mins, x_rng)\n",
    "X_test_n  = transform_minmax(X_test,  x_mins, x_rng)\n",
    "\n",
    "Y_train_n = transform_minmax(Y_train, y_mins, y_rng)\n",
    "Y_val_n   = transform_minmax(Y_val,   y_mins, y_rng)\n",
    "Y_test_n  = transform_minmax(Y_test,  y_mins, y_rng)\n",
    "\n",
    "# 5) Convert to torch tensors (ready for DataLoaders)\n",
    "X_train_t = torch.from_numpy(X_train_n)\n",
    "Y_train_t = torch.from_numpy(Y_train_n)\n",
    "X_val_t   = torch.from_numpy(X_val_n)\n",
    "Y_val_t   = torch.from_numpy(Y_val_n)\n",
    "X_test_t  = torch.from_numpy(X_test_n)\n",
    "Y_test_t  = torch.from_numpy(Y_test_n)\n",
    "\n",
    "print(\"Torch tensors:\",\n",
    "      X_train_t.shape, Y_train_t.shape,\n",
    "      X_val_t.shape,   Y_val_t.shape,\n",
    "      X_test_t.shape,  Y_test_t.shape)\n",
    "\n",
    "# Save normalization params for inference-time inverse-transform\n",
    "np.savez(\n",
    "    \"minmax_params_dnn_7_(lam).npz\",\n",
    "    x_mins=x_mins, x_rng=x_rng,\n",
    "    y_mins=y_mins, y_rng=y_rng\n",
    ")\n",
    "\n",
    "# Save splits as torch tensors\n",
    "data = {\n",
    "    \"X_train_t\": X_train_t,\n",
    "    \"Y_train_t\": Y_train_t,\n",
    "    \"X_val_t\":   X_val_t,\n",
    "    \"Y_val_t\":   Y_val_t,\n",
    "    \"X_test_t\":  X_test_t,\n",
    "    \"Y_test_t\":  Y_test_t,\n",
    "    \"X_train_n\": X_train_n,\n",
    "    \"Y_train_n\": Y_train_n,\n",
    "    \"X_val_n\":   X_val_n,\n",
    "    \"Y_val_n\":   Y_val_n,\n",
    "    \"X_test_n\":  X_test_n,\n",
    "    \"Y_test_n\":  Y_test_n,\n",
    "}\n",
    "\n",
    "# Save all in one file\n",
    "torch.save(data, 'datasets_dnn_7_(lam).pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8cade",
   "metadata": {},
   "source": [
    "### 2. \n",
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5279de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (67, 3) (67, 2) (67, 2)\n",
      "Val shapes: (14, 3) (14, 2) (14, 2)\n",
      "Test shapes: (14, 3) (14, 2) (14, 2)\n",
      "x_mins shape: (3,)\n",
      "y_mins shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# ----------------------------\n",
    "# Load datasets\n",
    "# ----------------------------\n",
    "loaded_data = np.load(\"saved_models/dnn_4_(ye)/datasets_dnn_4_(ye).npz\")\n",
    "\n",
    "Xn_train = loaded_data[\"Xn_train\"]\n",
    "Yn_train = loaded_data[\"Yn_train\"]\n",
    "Mn_train = loaded_data[\"Mn_train\"]\n",
    "Xn_val   = loaded_data[\"Xn_val\"]\n",
    "Yn_val   = loaded_data[\"Yn_val\"]\n",
    "Mn_val   = loaded_data[\"Mn_val\"]\n",
    "Xn_test  = loaded_data[\"Xn_test\"]\n",
    "Yn_test  = loaded_data[\"Yn_test\"]\n",
    "Mn_test  = loaded_data[\"Mn_test\"]\n",
    "\n",
    "print(\"Train shapes:\", Xn_train.shape, Yn_train.shape, Mn_train.shape)\n",
    "print(\"Val shapes:\",   Xn_val.shape,   Yn_val.shape,   Mn_val.shape)\n",
    "print(\"Test shapes:\",  Xn_test.shape,  Yn_test.shape,  Mn_test.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Load scaling params\n",
    "# ----------------------------\n",
    "loaded_data_n = np.load(\"saved_models/dnn_4_(ye)/minmax_params_dnn_4_(ye).npz\")\n",
    "x_mins = loaded_data_n[\"x_mins\"]\n",
    "x_rng  = loaded_data_n[\"x_rng\"]\n",
    "y_mins = loaded_data_n[\"y_mins\"]\n",
    "y_rng  = loaded_data_n[\"y_rng\"]\n",
    "\n",
    "print(\"x_mins shape:\", x_mins.shape)\n",
    "print(\"y_mins shape:\", y_mins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d473e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12  # numerical safety\n",
    "import torch.nn as nn\n",
    "HIDDEN = [128, 128, 128]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden=HIDDEN):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.ReLU()]\n",
    "            d = h\n",
    "        self.trunk = nn.Sequential(*layers)\n",
    "        self.head_lambda = nn.Linear(d, 1)   # -> λ\n",
    "        self.head_geom   = nn.Linear(d, 1)   # -> [H, L]\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.trunk(x)\n",
    "        lam = self.head_lambda(z)  # (B,1)\n",
    "        L  = self.head_geom(z)    # (B,1)\n",
    "        return lam, L\n",
    "    \n",
    "\n",
    "class XYMDataset(Dataset):\n",
    "    def __init__(self, X, Y, M):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "        self.M = torch.tensor(M, dtype=torch.float32)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i], self.M[i]\n",
    "\n",
    "def masked_mse(pred, target, mask, eps=EPS):\n",
    "    \"\"\"\n",
    "    pred, target, mask: (B,D)\n",
    "    Computes mean square error only over entries with mask=1.\n",
    "    \"\"\"\n",
    "    se = (pred - target)**2 * mask\n",
    "    denom = mask.sum().clamp_min(eps)\n",
    "    return se.sum() / denom\n",
    "\n",
    "def evaluate(dloader, model, tgt_min, tgt_rng, device=DEVICE):\n",
    "    \"\"\"Return MAE/MSE on the original (denormalized) scale for each target [λ,L].\"\"\"\n",
    "    model.eval()\n",
    "    mae = np.zeros(2, dtype=np.float64)\n",
    "    mse = np.zeros(2, dtype=np.float64)\n",
    "    count = np.zeros(2, dtype=np.float64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, mb in dloader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)        # normalized targets\n",
    "            mb = mb.to(device)\n",
    "\n",
    "            lam_pred, L_pred = model(xb)\n",
    "            pred = torch.cat([lam_pred, L_pred], dim=1)  # (B,3)\n",
    "\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            y_np    = yb.cpu().numpy()\n",
    "            m_np    = mb.cpu().numpy().astype(bool)\n",
    "\n",
    "            # inverse min-max per dim\n",
    "            for j in range(2):\n",
    "                p = pred_np[:, j] * tgt_rng[j] + tgt_min[j]\n",
    "                t = y_np[:, j]    * tgt_rng[j] + tgt_min[j]\n",
    "                m = m_np[:, j]\n",
    "                if m.any():\n",
    "                    diff = p[m] - t[m]\n",
    "                    mae[j] += np.abs(diff).sum()\n",
    "                    mse[j] += (diff**2).sum()\n",
    "                    count[j] += m.sum()\n",
    "\n",
    "    mae = np.where(count>0, mae/count, np.nan)\n",
    "    mse = np.where(count>0, mse/count, np.nan)\n",
    "    return mae, mse\n",
    "\n",
    "\n",
    "model = MultiHead(in_dim=3, hidden=HIDDEN).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc36b3",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c67b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 | train_loss ~ 4.1373e-02 | VA-MSE [λ,L]= [0.08998746 0.09116926]\n",
      "Epoch   10 | train_loss ~ 4.8548e-03 | VA-MSE [λ,L]= [0.00472731 0.01870024]\n",
      "Epoch   20 | train_loss ~ 4.3191e-03 | VA-MSE [λ,L]= [0.00500374 0.01659206]\n",
      "Epoch   30 | train_loss ~ 4.1343e-03 | VA-MSE [λ,L]= [0.00325355 0.01540937]\n",
      "Epoch   40 | train_loss ~ 3.4840e-03 | VA-MSE [λ,L]= [0.00115568 0.01094982]\n",
      "Epoch   50 | train_loss ~ 2.9145e-03 | VA-MSE [λ,L]= [0.00151675 0.00747611]\n",
      "Epoch   60 | train_loss ~ 2.4226e-03 | VA-MSE [λ,L]= [0.00080499 0.00385196]\n",
      "Epoch   70 | train_loss ~ 2.0902e-03 | VA-MSE [λ,L]= [0.00102408 0.00160871]\n",
      "Epoch   80 | train_loss ~ 1.9891e-03 | VA-MSE [λ,L]= [0.0011539  0.00175628]\n",
      "Epoch   90 | train_loss ~ 1.9179e-03 | VA-MSE [λ,L]= [0.00105761 0.00145025]\n",
      "Epoch  100 | train_loss ~ 1.8366e-03 | VA-MSE [λ,L]= [0.00097296 0.0010848 ]\n",
      "Epoch  110 | train_loss ~ 1.7552e-03 | VA-MSE [λ,L]= [0.00083958 0.00086617]\n",
      "Epoch  120 | train_loss ~ 1.6661e-03 | VA-MSE [λ,L]= [0.00075435 0.00072862]\n",
      "Epoch  130 | train_loss ~ 1.5698e-03 | VA-MSE [λ,L]= [0.00068126 0.00059609]\n",
      "Epoch  140 | train_loss ~ 1.4640e-03 | VA-MSE [λ,L]= [0.00067451 0.00050917]\n",
      "Epoch  150 | train_loss ~ 1.3551e-03 | VA-MSE [λ,L]= [0.00073683 0.00043713]\n",
      "Epoch  160 | train_loss ~ 1.2540e-03 | VA-MSE [λ,L]= [0.00084843 0.0003869 ]\n",
      "Epoch  170 | train_loss ~ 1.1610e-03 | VA-MSE [λ,L]= [0.00105077 0.00040434]\n",
      "Epoch  180 | train_loss ~ 1.0767e-03 | VA-MSE [λ,L]= [0.00134815 0.00035452]\n",
      "Epoch  190 | train_loss ~ 9.9838e-04 | VA-MSE [λ,L]= [0.00167816 0.00033252]\n",
      "Epoch  200 | train_loss ~ 9.3258e-04 | VA-MSE [λ,L]= [0.00204349 0.00034471]\n",
      "Epoch  210 | train_loss ~ 8.6428e-04 | VA-MSE [λ,L]= [0.00224944 0.00037214]\n",
      "Epoch  220 | train_loss ~ 7.9986e-04 | VA-MSE [λ,L]= [0.00267873 0.00042807]\n",
      "Epoch  230 | train_loss ~ 7.4097e-04 | VA-MSE [λ,L]= [0.00292412 0.00040173]\n",
      "Epoch  240 | train_loss ~ 6.8006e-04 | VA-MSE [λ,L]= [0.00350092 0.00036524]\n",
      "Epoch  250 | train_loss ~ 6.1291e-04 | VA-MSE [λ,L]= [0.00358362 0.00035567]\n",
      "Epoch  260 | train_loss ~ 5.5839e-04 | VA-MSE [λ,L]= [0.00382274 0.00039385]\n",
      "Epoch  270 | train_loss ~ 5.0565e-04 | VA-MSE [λ,L]= [0.00388665 0.00038607]\n",
      "Epoch  280 | train_loss ~ 4.5731e-04 | VA-MSE [λ,L]= [0.00410774 0.00042349]\n",
      "Epoch  290 | train_loss ~ 4.1253e-04 | VA-MSE [λ,L]= [0.00437201 0.0003298 ]\n",
      "Epoch  300 | train_loss ~ 3.6853e-04 | VA-MSE [λ,L]= [0.00446433 0.00037921]\n",
      "Epoch  310 | train_loss ~ 3.3029e-04 | VA-MSE [λ,L]= [0.00469984 0.00036118]\n",
      "Epoch  320 | train_loss ~ 2.9588e-04 | VA-MSE [λ,L]= [0.00502328 0.00035647]\n",
      "Epoch  330 | train_loss ~ 2.6555e-04 | VA-MSE [λ,L]= [0.00518703 0.0003499 ]\n",
      "Epoch  340 | train_loss ~ 2.5043e-04 | VA-MSE [λ,L]= [0.00584793 0.00032186]\n",
      "Epoch  350 | train_loss ~ 2.2314e-04 | VA-MSE [λ,L]= [0.00579619 0.00042294]\n",
      "Epoch  360 | train_loss ~ 2.0826e-04 | VA-MSE [λ,L]= [0.00630456 0.00028239]\n",
      "Epoch  370 | train_loss ~ 1.9876e-04 | VA-MSE [λ,L]= [0.00577989 0.00032024]\n",
      "Epoch  380 | train_loss ~ 1.9230e-04 | VA-MSE [λ,L]= [0.00640751 0.00034551]\n",
      "Epoch  390 | train_loss ~ 1.8024e-04 | VA-MSE [λ,L]= [0.00598887 0.00040974]\n",
      "Epoch  400 | train_loss ~ 1.7316e-04 | VA-MSE [λ,L]= [0.00607184 0.00035798]\n",
      "Epoch  410 | train_loss ~ 1.6694e-04 | VA-MSE [λ,L]= [0.00609881 0.00034723]\n",
      "Epoch  420 | train_loss ~ 1.6194e-04 | VA-MSE [λ,L]= [0.00604094 0.00039338]\n",
      "Epoch  430 | train_loss ~ 1.5894e-04 | VA-MSE [λ,L]= [0.00591454 0.00041577]\n",
      "Epoch  440 | train_loss ~ 1.5285e-04 | VA-MSE [λ,L]= [0.00573402 0.00043672]\n",
      "Epoch  450 | train_loss ~ 1.4927e-04 | VA-MSE [λ,L]= [0.00561858 0.00040071]\n",
      "Epoch  460 | train_loss ~ 1.4478e-04 | VA-MSE [λ,L]= [0.00590165 0.00041714]\n",
      "Epoch  470 | train_loss ~ 1.4331e-04 | VA-MSE [λ,L]= [0.00555383 0.00045664]\n",
      "Epoch  480 | train_loss ~ 1.4257e-04 | VA-MSE [λ,L]= [0.00565341 0.00042326]\n",
      "Epoch  490 | train_loss ~ 1.4196e-04 | VA-MSE [λ,L]= [0.0055587 0.0004424]\n",
      "Epoch  500 | train_loss ~ 1.4141e-04 | VA-MSE [λ,L]= [0.00558913 0.00043265]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = len(Xn_train)\n",
    "LR = 1e-3\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.1, patience=30)\n",
    "\n",
    "\n",
    "ds_tr = XYMDataset(Xn_train, Yn_train, Mn_train)\n",
    "ds_va = XYMDataset(Xn_val, Yn_val, Mn_val)\n",
    "ds_te = XYMDataset(Xn_test, Yn_test, Mn_test)\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "dl_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "dl_te = DataLoader(ds_te, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "valid_counts = Mn_train.sum(axis=0)  # (2,)\n",
    "w_lam = 1.0 / max(valid_counts[0], 1.0)\n",
    "w_geo = 1.0 / max(valid_counts[1], 1.0)\n",
    "\n",
    "losses_history = []\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb, mb in dl_tr:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)  # normalized targets\n",
    "        mb = mb.to(DEVICE)\n",
    "\n",
    "        lam_pred, L_pred = model(xb)          # (B,1), (B,1)\n",
    "        lam_t = yb[:, [0]]                      # (B,1)\n",
    "        L_t  = yb[:, [1]]                      # (B,1)\n",
    "        m_lam = mb[:, [0]]\n",
    "        m_geo = mb[:, [1]]\n",
    "\n",
    "        loss_lam = masked_mse(lam_pred, lam_t, m_lam)\n",
    "        loss_geo = masked_mse(L_pred,  L_t,  m_geo)\n",
    "\n",
    "        loss = w_lam * loss_lam + w_geo * loss_geo\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        _, mse_va = evaluate(dl_va, model, y_mins, y_rng)\n",
    "        scheduler.step(np.mean(mse_va))\n",
    "        losses_history.append([loss.item(), mse_va[0], mse_va[1]])\n",
    "        print(f\"Epoch {epoch:4d} | train_loss ~ {total_loss/len(ds_tr):.4e} | VA-MSE [λ,L]= {mse_va}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d4a5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "losses_history = np.array(losses_history)\n",
    "plt.plot(losses_history[:,0], label='Train Loss')\n",
    "plt.plot(losses_history[:,1], label='Val Loss λ')\n",
    "plt.plot(losses_history[:,2], label='Val Loss L')\n",
    "# plt.vlines(np.argmin(losses_history[:,1]), linestyles='--', ymin=0, ymax=max(losses_history[:,1]), label='min_L_val', color='gray')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06750ec3",
   "metadata": {},
   "source": [
    "### 4.\n",
    "Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4c16c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tgt_min' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Final evaluation on TEST\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mae_te, mse_te \u001b[38;5;241m=\u001b[39m evaluate(dl_te, model, \u001b[43mtgt_min\u001b[49m, tgt_rng)\n\u001b[0;32m      5\u001b[0m mape_te \u001b[38;5;241m=\u001b[39m mae_te \u001b[38;5;241m/\u001b[39m tgt_rng \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m  \u001b[38;5;66;03m# in percent\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST  MAPE [λ,H,L]:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mape_te, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tgt_min' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Final evaluation on TEST\n",
    "# -------------------\n",
    "mae_te, mse_te = evaluate(dl_te, model, tgt_min, tgt_rng)\n",
    "mape_te = mae_te / tgt_rng * 100.0  # in percent\n",
    "print(\"TEST  MAPE [λ,H,L]:\", mape_te, '%')\n",
    "print(\"TEST  MAE [λ,H,L]:\", mae_te)\n",
    "print(\"TEST  MSE [λ,H,L]:\", mse_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527636a",
   "metadata": {},
   "source": [
    "### 5.\n",
    "Optuna analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd10b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-08-24 13:08:52,326] A new study created in memory with name: dnn4_ye_mlp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (67, 3) (67, 2) (67, 2)\n",
      "Val shapes: (14, 3) (14, 2) (14, 2)\n",
      "Test shapes: (14, 3) (14, 2) (14, 2)\n",
      "x_mins shape: (3,)\n",
      "y_mins shape: (2,)\n",
      "Starting optimization for 40 trials…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:53,470] Trial 0 finished with value: 0.06001119315624237 and parameters: {'n_layers': 2, 'hidden_base': 64, 'width_decay': 0.7848501673009197, 'activation': 'relu', 'use_bn': False, 'dropout': 0.08493564427131046, 'lr': 0.00020366442026830908, 'weight_decay': 1.9223460470643654e-08, 'batch_size': 256, 'onecycle_pct_start': 0.09882285122821466, 'onecycle_div_factor': 18.146509184084817, 'onecycle_final_div_factor': 21.486282948216125}. Best is trial 0 with value: 0.06001119315624237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.00864188:   5%|▌         | 2/40 [00:02<00:43,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:54,542] Trial 1 finished with value: 0.008641880088382297 and parameters: {'n_layers': 3, 'hidden_base': 64, 'width_decay': 1.114526911140863, 'activation': 'gelu', 'use_bn': False, 'dropout': 0.039068845602553554, 'lr': 0.0014537555576161927, 'weight_decay': 1.2052231254145615e-06, 'batch_size': 192, 'onecycle_pct_start': 0.2818827995238937, 'onecycle_div_factor': 19.026998424023493, 'onecycle_final_div_factor': 28.403060953001486}. Best is trial 1 with value: 0.008641880088382297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:   8%|▊         | 3/40 [00:03<00:39,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:55,480] Trial 2 finished with value: 0.0013593744072649214 and parameters: {'n_layers': 3, 'hidden_base': 128, 'width_decay': 1.108739987286651, 'activation': 'relu', 'use_bn': True, 'dropout': 0.10853961270955836, 'lr': 0.0025585868855934266, 'weight_decay': 3.142485531883167e-07, 'batch_size': 192, 'onecycle_pct_start': 0.3954104278101811, 'onecycle_div_factor': 39.751014618349586, 'onecycle_final_div_factor': 13.942205669037758}. Best is trial 2 with value: 0.0013593744072649214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:  10%|█         | 4/40 [00:04<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:56,175] Trial 3 finished with value: 0.006670917467110687 and parameters: {'n_layers': 1, 'hidden_base': 64, 'width_decay': 0.9650794371265636, 'activation': 'leaky_relu', 'use_bn': True, 'dropout': 0.13007332881069883, 'lr': 0.00173611708903933, 'weight_decay': 2.9033694281285655e-05, 'batch_size': 64, 'onecycle_pct_start': 0.2464470191493237, 'onecycle_div_factor': 39.69352309795524, 'onecycle_final_div_factor': 27.220801836397584}. Best is trial 2 with value: 0.0013593744072649214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:  10%|█         | 4/40 [00:04<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:57,307] Trial 4 finished with value: 0.001710804696712229 and parameters: {'n_layers': 3, 'hidden_base': 512, 'width_decay': 0.938613588645796, 'activation': 'leaky_relu', 'use_bn': False, 'dropout': 0.0307919639315172, 'lr': 0.0003106554858581908, 'weight_decay': 1.3444634828135546e-08, 'batch_size': 64, 'onecycle_pct_start': 0.11529952061011255, 'onecycle_div_factor': 45.165154932049, 'onecycle_final_div_factor': 29.270400886204282}. Best is trial 2 with value: 0.0013593744072649214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:  15%|█▌        | 6/40 [00:05<00:29,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:57,996] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:  15%|█▌        | 6/40 [00:05<00:29,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:58,225] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:  20%|██        | 8/40 [00:06<00:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:08:58,663] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.00135937:  20%|██        | 8/40 [00:12<00:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:04,557] Trial 8 finished with value: 0.0015196796506643296 and parameters: {'n_layers': 5, 'hidden_base': 512, 'width_decay': 1.2822518545590704, 'activation': 'relu', 'use_bn': False, 'dropout': 0.0036788206466518594, 'lr': 0.00014872949647124203, 'weight_decay': 4.4107494004092403e-05, 'batch_size': 192, 'onecycle_pct_start': 0.12849425831119593, 'onecycle_div_factor': 37.04806496063912, 'onecycle_final_div_factor': 15.676208937356003}. Best is trial 2 with value: 0.0013593744072649214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  25%|██▌       | 10/40 [00:13<01:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:06,036] Trial 9 finished with value: 0.0013181126573019557 and parameters: {'n_layers': 2, 'hidden_base': 256, 'width_decay': 0.8062048606968555, 'activation': 'gelu', 'use_bn': True, 'dropout': 0.25245545039890516, 'lr': 0.002240580561294616, 'weight_decay': 3.2995875156654844e-06, 'batch_size': 192, 'onecycle_pct_start': 0.05851058825100885, 'onecycle_div_factor': 34.046253315822554, 'onecycle_final_div_factor': 12.969980573317201}. Best is trial 9 with value: 0.0013181126573019557.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  28%|██▊       | 11/40 [00:14<00:43,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:06,353] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  30%|███       | 12/40 [00:15<00:37,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:07,390] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  32%|███▎      | 13/40 [00:15<00:31,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:08,075] Trial 12 finished with value: 0.0016482224558583562 and parameters: {'n_layers': 2, 'hidden_base': 384, 'width_decay': 0.8262363075911309, 'activation': 'leaky_relu', 'use_bn': False, 'dropout': 0.21254185262725922, 'lr': 0.0008289395383720047, 'weight_decay': 2.8974057021683085e-05, 'batch_size': 96, 'onecycle_pct_start': 0.144791287941726, 'onecycle_div_factor': 24.753713931753623, 'onecycle_final_div_factor': 8.530537160401968}. Best is trial 9 with value: 0.0013181126573019557.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  32%|███▎      | 13/40 [00:15<00:31,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:08,326] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  38%|███▊      | 15/40 [00:16<00:20,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:09,049] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  38%|███▊      | 15/40 [00:17<00:20,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:09,909] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  42%|████▎     | 17/40 [00:18<00:15,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:10,284] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  42%|████▎     | 17/40 [00:18<00:15,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:10,694] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  48%|████▊     | 19/40 [00:19<00:12,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:11,217] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.00131811:  48%|████▊     | 19/40 [00:20<00:12,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:12,816] Trial 19 finished with value: 0.001152014582314425 and parameters: {'n_layers': 4, 'hidden_base': 384, 'width_decay': 1.1974403837875804, 'activation': 'relu', 'use_bn': True, 'dropout': 0.20084942141151835, 'lr': 0.004628537768766658, 'weight_decay': 1.2599410048603526e-06, 'batch_size': 192, 'onecycle_pct_start': 0.051638847745202436, 'onecycle_div_factor': 31.138874803846253, 'onecycle_final_div_factor': 17.654472286554437}. Best is trial 19 with value: 0.001152014582314425.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  50%|█████     | 20/40 [00:22<00:17,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:14,595] Trial 20 finished with value: 0.0010648748113049403 and parameters: {'n_layers': 4, 'hidden_base': 384, 'width_decay': 0.7579075286285542, 'activation': 'relu', 'use_bn': True, 'dropout': 0.18978883452749565, 'lr': 0.004276662802628943, 'weight_decay': 1.6480469992853966e-06, 'batch_size': 192, 'onecycle_pct_start': 0.0710735446100558, 'onecycle_div_factor': 30.816026037751634, 'onecycle_final_div_factor': 23.037457839999973}. Best is trial 20 with value: 0.0010648748113049403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  52%|█████▎    | 21/40 [00:22<00:21,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:15,093] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  55%|█████▌    | 22/40 [00:23<00:17,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:15,673] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  60%|██████    | 24/40 [00:26<00:22,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:18,493] Trial 23 finished with value: 0.0013230406006591187 and parameters: {'n_layers': 4, 'hidden_base': 384, 'width_decay': 1.3463056710298253, 'activation': 'relu', 'use_bn': True, 'dropout': 0.31719791981438855, 'lr': 0.004783220826501964, 'weight_decay': 0.006516343766012702, 'batch_size': 192, 'onecycle_pct_start': 0.05251302696081619, 'onecycle_div_factor': 22.174223521901624, 'onecycle_final_div_factor': 24.123523796220503}. Best is trial 20 with value: 0.0010648748113049403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  60%|██████    | 24/40 [00:26<00:22,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:18,853] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  65%|██████▌   | 26/40 [00:27<00:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:19,245] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  65%|██████▌   | 26/40 [00:27<00:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:19,608] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  68%|██████▊   | 27/40 [00:27<00:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:20,165] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.00106487:  70%|███████   | 28/40 [00:28<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:20,545] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.000798897:  75%|███████▌  | 30/40 [00:29<00:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:21,415] Trial 29 finished with value: 0.0007988970416287582 and parameters: {'n_layers': 3, 'hidden_base': 384, 'width_decay': 0.7953848863420618, 'activation': 'relu', 'use_bn': False, 'dropout': 0.07505929472155237, 'lr': 0.0031963763475357553, 'weight_decay': 9.853761065646011e-05, 'batch_size': 256, 'onecycle_pct_start': 0.1592664006926158, 'onecycle_div_factor': 42.7927305281726, 'onecycle_final_div_factor': 33.569680181977944}. Best is trial 29 with value: 0.0007988970416287582.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.000798897:  75%|███████▌  | 30/40 [00:30<00:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:22,493] Trial 30 finished with value: 0.0011994751687679026 and parameters: {'n_layers': 4, 'hidden_base': 384, 'width_decay': 0.7531087756074548, 'activation': 'relu', 'use_bn': False, 'dropout': 0.09055952937918241, 'lr': 0.00338913023908257, 'weight_decay': 0.000123960171069589, 'batch_size': 256, 'onecycle_pct_start': 0.16316045064029813, 'onecycle_div_factor': 43.094797331153686, 'onecycle_final_div_factor': 33.729674978745464}. Best is trial 29 with value: 0.0007988970416287582.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.000798897:  80%|████████  | 32/40 [00:31<00:07,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:23,752] Trial 31 finished with value: 0.0009535143255359597 and parameters: {'n_layers': 4, 'hidden_base': 384, 'width_decay': 0.7577752108644964, 'activation': 'relu', 'use_bn': False, 'dropout': 0.08037462315705518, 'lr': 0.0034402181267471623, 'weight_decay': 0.00011140605494173632, 'batch_size': 256, 'onecycle_pct_start': 0.15645042870719342, 'onecycle_div_factor': 43.45854326042896, 'onecycle_final_div_factor': 34.132373981116736}. Best is trial 29 with value: 0.0007988970416287582.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.000798897:  82%|████████▎ | 33/40 [00:32<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:24,617] Trial 32 finished with value: 0.0009228804252213902 and parameters: {'n_layers': 3, 'hidden_base': 384, 'width_decay': 0.7874153933329707, 'activation': 'relu', 'use_bn': False, 'dropout': 0.06222825956421066, 'lr': 0.0029964529873017106, 'weight_decay': 0.00010733772221721085, 'batch_size': 256, 'onecycle_pct_start': 0.2263144519556813, 'onecycle_div_factor': 45.60085220355162, 'onecycle_final_div_factor': 41.597030835882656}. Best is trial 29 with value: 0.0007988970416287582.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  85%|████████▌ | 34/40 [00:33<00:05,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:25,390] Trial 33 finished with value: 0.0007739484672331148 and parameters: {'n_layers': 3, 'hidden_base': 384, 'width_decay': 0.8664738055054954, 'activation': 'relu', 'use_bn': False, 'dropout': 0.06245607537731081, 'lr': 0.003078851961859269, 'weight_decay': 0.0001253137040781871, 'batch_size': 256, 'onecycle_pct_start': 0.22727562256006456, 'onecycle_div_factor': 46.85370811520835, 'onecycle_final_div_factor': 41.866738942010436}. Best is trial 33 with value: 0.0007739484672331148.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  88%|████████▊ | 35/40 [00:33<00:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:25,693] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  88%|████████▊ | 35/40 [00:33<00:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:26,003] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  92%|█████████▎| 37/40 [00:34<00:01,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:26,443] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  95%|█████████▌| 38/40 [00:34<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:26,776] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  98%|█████████▊| 39/40 [00:35<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:27,529] Trial 38 finished with value: 0.000966511159721348 and parameters: {'n_layers': 3, 'hidden_base': 384, 'width_decay': 0.7917241363467362, 'activation': 'leaky_relu', 'use_bn': False, 'dropout': 0.10377022518230188, 'lr': 0.0029097334461818188, 'weight_decay': 8.244555509035664e-05, 'batch_size': 256, 'onecycle_pct_start': 0.15957574943333258, 'onecycle_div_factor': 47.02335335210338, 'onecycle_final_div_factor': 35.67110619673481}. Best is trial 33 with value: 0.0007739484672331148.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948:  98%|█████████▊| 39/40 [00:36<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 13:09:28,614] Trial 39 finished with value: 0.0008699904454665051 and parameters: {'n_layers': 3, 'hidden_base': 512, 'width_decay': 0.8392803126761115, 'activation': 'relu', 'use_bn': False, 'dropout': 0.020652043439086547, 'lr': 0.002006765879441957, 'weight_decay': 0.00024005682265209967, 'batch_size': 256, 'onecycle_pct_start': 0.28896218315492606, 'onecycle_div_factor': 39.658887363181435, 'onecycle_final_div_factor': 41.979187211006554}. Best is trial 33 with value: 0.0007739484672331148.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.000773948: 100%|██████████| 40/40 [00:36<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.6 min\n",
      "Best trial: 33\n",
      "Best value (Val MSE mean denorm): 0.0007739484672331148\n",
      "Best params: {'n_layers': 3, 'hidden_base': 384, 'width_decay': 0.8664738055054954, 'activation': 'relu', 'use_bn': False, 'dropout': 0.06245607537731081, 'lr': 0.003078851961859269, 'weight_decay': 0.0001253137040781871, 'batch_size': 256, 'onecycle_pct_start': 0.22727562256006456, 'onecycle_div_factor': 46.85370811520835, 'onecycle_final_div_factor': 41.866738942010436}\n",
      "\n",
      "Final metrics (denormalized):\n",
      "Train MAE: [0.05606569846471151, 0.023435071457264034] MSE: [0.00572521115342776, 0.0008232253062170605]\n",
      "Val   MAE: [0.04352717399597168, 0.022299634085761175] MSE: [0.0024941118434071543, 0.0008250957147942649]\n",
      "Test  MAE: [0.01912568509578705, 0.031939220428466794] MSE: [0.0003842164878733456, 0.0013105053454637527]\n",
      "\n",
      "Saved best model to: saved_models/dnn_4_(ye)\\optuna_best.pth\n",
      "Saved best params to: saved_models/dnn_4_(ye)\\optuna_best_params.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optuna_dnn_study.py\n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------------\n",
    "# Repro & device\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------------------\n",
    "# Load datasets\n",
    "# ----------------------------\n",
    "ROOT = \"saved_models/dnn_4_(ye)\"\n",
    "data_npz = os.path.join(ROOT, \"datasets_dnn_4_(ye).npz\")\n",
    "scal_npz = os.path.join(ROOT, \"minmax_params_dnn_4_(ye).npz\")\n",
    "\n",
    "loaded = np.load(data_npz)\n",
    "Xn_train = loaded[\"Xn_train\"]; Yn_train = loaded[\"Yn_train\"]; Mn_train = loaded[\"Mn_train\"]\n",
    "Xn_val   = loaded[\"Xn_val\"];   Yn_val   = loaded[\"Yn_val\"];   Mn_val   = loaded[\"Mn_val\"]\n",
    "Xn_test  = loaded[\"Xn_test\"];  Yn_test  = loaded[\"Yn_test\"];  Mn_test  = loaded[\"Mn_test\"]\n",
    "\n",
    "loaded_n = np.load(scal_npz)\n",
    "x_mins = loaded_n[\"x_mins\"]; x_rng = loaded_n[\"x_rng\"]\n",
    "y_mins = loaded_n[\"y_mins\"]; y_rng = loaded_n[\"y_rng\"]\n",
    "\n",
    "print(\"Train shapes:\", Xn_train.shape, Yn_train.shape, Mn_train.shape)\n",
    "print(\"Val shapes:\",   Xn_val.shape,   Yn_val.shape,   Mn_val.shape)\n",
    "print(\"Test shapes:\",  Xn_test.shape,  Yn_test.shape,  Mn_test.shape)\n",
    "print(\"x_mins shape:\", x_mins.shape)\n",
    "print(\"y_mins shape:\", y_mins.shape)\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset & helpers\n",
    "# ----------------------------\n",
    "class XYMDataset(Dataset):\n",
    "    def __init__(self, X, Y, M):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "        self.M = torch.tensor(M, dtype=torch.float32)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i], self.M[i]\n",
    "\n",
    "def masked_mse(pred, target, mask, eps=EPS):\n",
    "    # pred, target, mask: (B, D) with D=2 here\n",
    "    se = (pred - target)**2 * mask\n",
    "    denom = mask.sum().clamp_min(eps)\n",
    "    return se.sum() / denom\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_denorm(dloader, model, tgt_min, tgt_rng, device=DEVICE):\n",
    "    \"\"\"MAE/MSE on original (denormalized) scale for each of the two targets.\"\"\"\n",
    "    model.eval()\n",
    "    mae = np.zeros(2, dtype=np.float64)\n",
    "    mse = np.zeros(2, dtype=np.float64)\n",
    "    count = np.zeros(2, dtype=np.float64)\n",
    "\n",
    "    for xb, yb, mb in dloader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)        # normalized targets\n",
    "        mb = mb.to(device)\n",
    "\n",
    "        lam_pred, L_pred = model(xb)\n",
    "        pred = torch.cat([lam_pred, L_pred], dim=1)  # (B, 2)\n",
    "\n",
    "        pred_np = pred.cpu().numpy()\n",
    "        y_np    = yb.cpu().numpy()\n",
    "        m_np    = mb.cpu().numpy().astype(bool)\n",
    "\n",
    "        for j in range(2):\n",
    "            p = pred_np[:, j] * tgt_rng[j] + tgt_min[j]\n",
    "            t = y_np[:, j]    * tgt_rng[j] + tgt_min[j]\n",
    "            m = m_np[:, j]\n",
    "            if m.any():\n",
    "                diff = p[m] - t[m]\n",
    "                mae[j] += np.abs(diff).sum()\n",
    "                mse[j] += (diff**2).sum()\n",
    "                count[j] += m.sum()\n",
    "\n",
    "    mae = np.where(count>0, mae/count, np.nan)\n",
    "    mse = np.where(count>0, mse/count, np.nan)\n",
    "    return mae, mse\n",
    "\n",
    "# ----------------------------\n",
    "# Flexible model to search\n",
    "# ----------------------------\n",
    "class FlexibleMultiHead(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden_layers=(128,128,128),\n",
    "                 activation=\"relu\", dropout=0.0, use_bn=False):\n",
    "        super().__init__()\n",
    "        acts = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"leaky_relu\": lambda: nn.LeakyReLU(negative_slope=0.01),\n",
    "            \"elu\": nn.ELU,\n",
    "            \"gelu\": nn.GELU,\n",
    "        }\n",
    "        Act = acts[activation]\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(d, h))\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(Act())\n",
    "            if dropout and dropout > 0:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "            d = h\n",
    "        self.trunk = nn.Sequential(*layers) if layers else nn.Identity()\n",
    "        self.head_lambda = nn.Linear(d, 1)  # -> λ\n",
    "        self.head_geom   = nn.Linear(d, 1)  # -> L\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.trunk(x)\n",
    "        lam = self.head_lambda(z)\n",
    "        L   = self.head_geom(z)\n",
    "        return lam, L\n",
    "\n",
    "# ----------------------------\n",
    "# Dataloaders (kept outside for speed)\n",
    "# ----------------------------\n",
    "def make_loaders(batch_size: int):\n",
    "    train_ds = XYMDataset(Xn_train, Yn_train, Mn_train)\n",
    "    val_ds   = XYMDataset(Xn_val,   Yn_val,   Mn_val)\n",
    "    test_ds  = XYMDataset(Xn_test,  Yn_test,  Mn_test)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# ----------------------------\n",
    "# Objective\n",
    "# ----------------------------\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Search space\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    hidden_base = trial.suggest_categorical(\"hidden_base\", [64, 128, 256, 384, 512])\n",
    "    width_decay = trial.suggest_float(\"width_decay\", 0.75, 1.35)  # geometric taper/expand\n",
    "    hidden_layers = [int(max(32, round(hidden_base * (width_decay ** i)))) for i in range(n_layers)]\n",
    "\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\", \"elu\", \"gelu\"])\n",
    "    use_bn = trial.suggest_categorical(\"use_bn\", [False, True])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-9, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 96, 128, 192, 256])\n",
    "\n",
    "    max_epochs = 80\n",
    "    patience = 12  # early stopping on denorm val MSE\n",
    "    train_loader, val_loader, _ = make_loaders(batch_size)\n",
    "\n",
    "    model = FlexibleMultiHead(\n",
    "        in_dim=Xn_train.shape[1],\n",
    "        hidden_layers=tuple(hidden_layers),\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        use_bn=use_bn\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # OneCycleLR often works well for MLPs\n",
    "    steps_per_epoch = max(1, math.ceil(len(train_loader)))\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=lr,\n",
    "        epochs=max_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        pct_start=trial.suggest_float(\"onecycle_pct_start\", 0.05, 0.4),\n",
    "        div_factor=trial.suggest_float(\"onecycle_div_factor\", 5.0, 50.0),\n",
    "        final_div_factor=trial.suggest_float(\"onecycle_final_div_factor\", 5.0, 50.0),\n",
    "        three_phase=False,\n",
    "        anneal_strategy=\"cos\"\n",
    "    )\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running = 0.0; denom = 0.0\n",
    "\n",
    "        for xb, yb, mb in train_loader:\n",
    "            xb = xb.to(DEVICE); yb = yb.to(DEVICE); mb = mb.to(DEVICE)\n",
    "            lam_pred, L_pred = model(xb)\n",
    "            pred = torch.cat([lam_pred, L_pred], dim=1)  # (B, 2)\n",
    "\n",
    "            loss = masked_mse(pred, yb, mb)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            bsz = xb.size(0)\n",
    "            running += loss.item() * bsz\n",
    "            denom += bsz\n",
    "\n",
    "        # Validation (denormalized)\n",
    "        val_mae, val_mse = evaluate_denorm(val_loader, model, y_mins, y_rng, device=DEVICE)\n",
    "        metric = float(np.nanmean(val_mse))  # mean over the two targets\n",
    "\n",
    "        trial.report(metric, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        if metric + 1e-12 < best_val:\n",
    "            best_val = metric\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                break  # early stop\n",
    "\n",
    "    # Save the last-best weights to the trial for optional retrieval\n",
    "    trial.set_user_attr(\"best_val_mse\", best_val)\n",
    "    trial.set_user_attr(\"best_state_dict\", best_state)\n",
    "    return best_val\n",
    "\n",
    "# ----------------------------\n",
    "# Run study\n",
    "# ----------------------------\n",
    "def main():\n",
    "    storage = None  # set to f\"sqlite:///{ROOT}/optuna_dnn4_ye.db\" if you want persistence\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"dnn4_ye_mlp\",\n",
    "        direction=\"minimize\",\n",
    "        storage=storage,\n",
    "        load_if_exists=False,\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED, n_startup_trials=15),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "    )\n",
    "    n_trials = 40  # adjust as you like\n",
    "    print(f\"Starting optimization for {n_trials} trials…\")\n",
    "    start = time.time()\n",
    "    study.optimize(objective, n_trials=n_trials, gc_after_trial=True, show_progress_bar=True)\n",
    "    dur = time.time() - start\n",
    "    print(f\"Done in {dur/60:.1f} min\")\n",
    "    print(\"Best trial:\", study.best_trial.number)\n",
    "    print(\"Best value (Val MSE mean denorm):\", study.best_value)\n",
    "    print(\"Best params:\", study.best_params)\n",
    "\n",
    "    # ------------------------\n",
    "    # Re-train best OR restore saved best_state and evaluate on test\n",
    "    # ------------------------\n",
    "    best = study.best_trial\n",
    "    hidden_layers = [int(max(32, round(best.params[\"hidden_base\"] * (best.params[\"width_decay\"] ** i))))\n",
    "                     for i in range(best.params[\"n_layers\"])]\n",
    "    model = FlexibleMultiHead(\n",
    "        in_dim=Xn_train.shape[1],\n",
    "        hidden_layers=tuple(hidden_layers),\n",
    "        activation=best.params[\"activation\"],\n",
    "        dropout=best.params[\"dropout\"],\n",
    "        use_bn=best.params[\"use_bn\"]\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Load best weights captured during the trial\n",
    "    state = best.user_attrs.get(\"best_state_dict\", None)\n",
    "    if state is not None:\n",
    "        model.load_state_dict(state, strict=True)\n",
    "    else:\n",
    "        # rare fallback: quick fine-tune with the best params\n",
    "        train_loader, val_loader, _ = make_loaders(best.params[\"batch_size\"])\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=best.params[\"lr\"], weight_decay=best.params[\"weight_decay\"])\n",
    "        for _ in range(10):\n",
    "            model.train()\n",
    "            for xb, yb, mb in train_loader:\n",
    "                xb = xb.to(DEVICE); yb = yb.to(DEVICE); mb = mb.to(DEVICE)\n",
    "                lam_pred, L_pred = model(xb)\n",
    "                pred = torch.cat([lam_pred, L_pred], dim=1)\n",
    "                loss = masked_mse(pred, yb, mb)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                opt.step()\n",
    "\n",
    "    # Final evaluation on all splits (denormalized)\n",
    "    bs = best.params[\"batch_size\"]\n",
    "    train_loader, val_loader, test_loader = make_loaders(bs)\n",
    "    tr_mae, tr_mse = evaluate_denorm(train_loader, model, y_mins, y_rng, device=DEVICE)\n",
    "    va_mae, va_mse = evaluate_denorm(val_loader,   model, y_mins, y_rng, device=DEVICE)\n",
    "    te_mae, te_mse = evaluate_denorm(test_loader,  model, y_mins, y_rng, device=DEVICE)\n",
    "\n",
    "    print(\"\\nFinal metrics (denormalized):\")\n",
    "    def fmt(a): return [float(x) if np.isfinite(x) else None for x in a]\n",
    "    print(\"Train MAE:\", fmt(tr_mae), \"MSE:\", fmt(tr_mse))\n",
    "    print(\"Val   MAE:\", fmt(va_mae), \"MSE:\", fmt(va_mse))\n",
    "    print(\"Test  MAE:\", fmt(te_mae), \"MSE:\", fmt(te_mse))\n",
    "\n",
    "    # Save artifacts\n",
    "    os.makedirs(ROOT, exist_ok=True)\n",
    "    best_model_path = os.path.join(ROOT, \"optuna_best.pth\")\n",
    "    torch.save(model.state_dict(), best_model_path)\n",
    "    best_params_path = os.path.join(ROOT, \"optuna_best_params.json\")\n",
    "    with open(best_params_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"best_value_val_mse_mean_denorm\": study.best_value,\n",
    "            \"best_params\": study.best_params,\n",
    "            \"train_mae\": fmt(tr_mae), \"train_mse\": fmt(tr_mse),\n",
    "            \"val_mae\": fmt(va_mae),   \"val_mse\": fmt(va_mse),\n",
    "            \"test_mae\": fmt(te_mae),  \"test_mse\": fmt(te_mse),\n",
    "            \"arch_hidden_layers\": hidden_layers\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\nSaved best model to: {best_model_path}\")\n",
    "    print(f\"Saved best params to: {best_params_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
