{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afbd7f7",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Import data, split and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f56578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "DTYPE = np.float32\n",
    "\n",
    "def fit_minmax(X):\n",
    "    \"\"\"Fit per-feature min-max on X (2D). Returns (mins, ranges) with safe ranges.\"\"\"\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    rng = maxs - mins\n",
    "    rng_safe = np.where(rng > 0, rng, 1.0)  # avoid division by zero (constant features)\n",
    "    return mins.astype(DTYPE), rng_safe.astype(DTYPE)\n",
    "\n",
    "def transform_minmax(X, mins, rng_safe):\n",
    "    return ((X - mins) / rng_safe).astype(DTYPE)\n",
    "\n",
    "def inverse_minmax(X_scaled, mins, rng_safe):\n",
    "    return (X_scaled * rng_safe + mins).astype(DTYPE)\n",
    "\n",
    "def split_indices(n, val_frac=0.15, test_frac=0.15, rng=rng):\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    n_test = int(round(test_frac * n))\n",
    "    n_val  = int(round(val_frac * n))\n",
    "    n_train = n - n_val - n_test\n",
    "    return idx[:n_train], idx[n_train:n_train+n_val], idx[n_train+n_val:]\n",
    "\n",
    "def create_inp_out(df):\n",
    "    X_list, Y_list, M_list = [], [], []  # M is mask\n",
    "    for _, row in df.iterrows():\n",
    "        dV_ges = float(row[\"dV_ges\"]) / 3.6 * 1e-6\n",
    "        eps_0  = float(row[\"eps_0\"])\n",
    "        phi_0  = float(row[\"phi_0\"])\n",
    "        lam    = float(row[\"lambda\"])\n",
    "        H      = float(row[\"H_DPZ\"])\n",
    "        L      = float(row[\"L_DPZ\"])\n",
    "\n",
    "        X_list.append([dV_ges, eps_0, phi_0])\n",
    "\n",
    "        y = [lam, H, L]\n",
    "        m = [1.0 if v != -1.0 else 0.0 for v in y]\n",
    "        Y_list.append(y)\n",
    "        M_list.append(m)\n",
    "\n",
    "    X = np.asarray(X_list, dtype=DTYPE)\n",
    "    Y = np.asarray(Y_list, dtype=DTYPE)\n",
    "    M = np.asarray(M_list, dtype=DTYPE)\n",
    "    return X, Y, M\n",
    "\n",
    "\n",
    "class XYMDataset(Dataset):\n",
    "    def __init__(self, X, Y, M):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "        self.M = torch.tensor(M, dtype=torch.float32)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i], self.M[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79702ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRAC, VAL_FRAC, TEST_FRAC = 0.70, 0.15, 0.15\n",
    "torch.manual_seed(SEED)\n",
    "CSV_PATH = os.path.join(\"Input\", \"ye.csv\")\n",
    "\n",
    "# 1) Read original CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 2) Create input-output pairs\n",
    "X, Y, M = create_inp_out(df)\n",
    "N = X.shape[0]\n",
    "\n",
    "# 3) Split \n",
    "i_tr, i_va, i_te = split_indices(N, VAL_FRAC, TEST_FRAC, rng)\n",
    "X_train, Y_train, M_train = X[i_tr], Y[i_tr], M[i_tr]\n",
    "X_val, Y_val, M_val = X[i_va], Y[i_va], M[i_va]\n",
    "X_test, Y_test, M_test = X[i_te], Y[i_te], M[i_te]\n",
    "\n",
    "\n",
    "# 4) Normalize only present labels in TRAIN\n",
    "min_X, rng_X = fit_minmax(X_train)\n",
    "\n",
    "# Targets: fit per-dimension using only \n",
    "tgt_min = np.zeros(3, dtype=DTYPE)\n",
    "tgt_rng = np.ones(3, dtype=DTYPE)\n",
    "\n",
    "for j in range(3):\n",
    "    present = (M_train[:, j] == 1.0)\n",
    "    if present.any():\n",
    "        mins_j, rngs_j = fit_minmax(Y_train[present, [j]])\n",
    "        tgt_min[j] = mins_j.item()\n",
    "        tgt_rng[j] = rngs_j.item()\n",
    "    else:\n",
    "        # No labels for this target in train: keep default min=0, rng=1 (won't be used)\n",
    "        tgt_min[j] = 0.0\n",
    "        tgt_rng[j] = 1.0\n",
    "\n",
    "# -------------------\n",
    "# Transform splits (normalize only where target labels exist)\n",
    "# -------------------\n",
    "def transform_split_minmax(X, Y, M, min_X, rng_X, tgt_min, tgt_rng):\n",
    "    Xn = transform_minmax(X, min_X, rng_X)\n",
    "    Yn = Y.copy()\n",
    "    for j in range(3):\n",
    "        present = (M[:, j] == 1.0)\n",
    "        Yn[present, j] = (Yn[present, j] - tgt_min[j]) / tgt_rng[j]\n",
    "    return Xn, Yn, M\n",
    "\n",
    "Xn_train, Yn_train, Mn_train = transform_split_minmax(X_train, Y_train, M_train, min_X, rng_X, tgt_min, tgt_rng)\n",
    "Xn_val, Yn_val, Mn_val = transform_split_minmax(X_val, Y_val, M_val, min_X, rng_X, tgt_min, tgt_rng)\n",
    "Xn_test, Yn_test, Mn_test = transform_split_minmax(X_test, Y_test, M_test, min_X, rng_X, tgt_min, tgt_rng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8cade",
   "metadata": {},
   "source": [
    "### 2. \n",
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d473e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12  # numerical safety\n",
    "import torch.nn as nn\n",
    "HIDDEN = [128, 128, 128]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden=HIDDEN):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.ReLU()]\n",
    "            d = h\n",
    "        self.trunk = nn.Sequential(*layers)\n",
    "        self.head_lambda = nn.Linear(d, 1)   # -> λ\n",
    "        self.head_geom   = nn.Linear(d, 2)   # -> [H, L]\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.trunk(x)\n",
    "        lam = self.head_lambda(z)  # (B,1)\n",
    "        HL  = self.head_geom(z)    # (B,2)\n",
    "        return lam, HL\n",
    "\n",
    "def masked_mse(pred, target, mask, eps=EPS):\n",
    "    \"\"\"\n",
    "    pred, target, mask: (B,D)\n",
    "    Computes mean square error only over entries with mask=1.\n",
    "    \"\"\"\n",
    "    se = (pred - target)**2 * mask\n",
    "    denom = mask.sum().clamp_min(eps)\n",
    "    return se.sum() / denom\n",
    "\n",
    "def evaluate(dloader, model, tgt_min, tgt_rng, device=DEVICE):\n",
    "    \"\"\"Return MAE/MSE on the original (denormalized) scale for each target [λ,H,L].\"\"\"\n",
    "    model.eval()\n",
    "    mae = np.zeros(3, dtype=np.float64)\n",
    "    mse = np.zeros(3, dtype=np.float64)\n",
    "    count = np.zeros(3, dtype=np.float64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, mb in dloader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)        # normalized targets\n",
    "            mb = mb.to(device)\n",
    "\n",
    "            lam_pred, HL_pred = model(xb)\n",
    "            pred = torch.cat([lam_pred, HL_pred], dim=1)  # (B,3)\n",
    "\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            y_np    = yb.cpu().numpy()\n",
    "            m_np    = mb.cpu().numpy().astype(bool)\n",
    "\n",
    "            # inverse min-max per dim\n",
    "            for j in range(3):\n",
    "                p = pred_np[:, j] * tgt_rng[j] + tgt_min[j]\n",
    "                t = y_np[:, j]    * tgt_rng[j] + tgt_min[j]\n",
    "                m = m_np[:, j]\n",
    "                if m.any():\n",
    "                    diff = p[m] - t[m]\n",
    "                    mae[j] += np.abs(diff).sum()\n",
    "                    mse[j] += (diff**2).sum()\n",
    "                    count[j] += m.sum()\n",
    "\n",
    "    mae = np.where(count>0, mae/count, np.nan)\n",
    "    mse = np.where(count>0, mse/count, np.nan)\n",
    "    return mae, mse\n",
    "\n",
    "\n",
    "model = MultiHead(in_dim=3, hidden=HIDDEN).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc36b3",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c67b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 | train_loss ~ 2.7647e-02 | VA-MAE [λ,H,L]= [0.11655438 0.02465879 0.12494775] | VA-MSE [λ,H,L]= [0.01917257 0.00080122 0.02712737]\n",
      "Epoch  100 | train_loss ~ 1.4183e-03 | VA-MAE [λ,H,L]= [0.05648899 0.00309906 0.03317885] | VA-MSE [λ,H,L]= [1.16157407e-02 1.12452615e-05 1.72498525e-03]\n",
      "Epoch  200 | train_loss ~ 7.2619e-04 | VA-MAE [λ,H,L]= [0.05383626 0.00481178 0.03670461] | VA-MSE [λ,H,L]= [1.15111880e-02 4.37874009e-05 2.31883357e-03]\n",
      "Epoch  300 | train_loss ~ 5.3578e-04 | VA-MAE [λ,H,L]= [0.04856056 0.00613807 0.03448819] | VA-MSE [λ,H,L]= [8.80592960e-03 7.51765841e-05 1.67715494e-03]\n",
      "Epoch  400 | train_loss ~ 5.3901e-04 | VA-MAE [λ,H,L]= [0.04447352 0.00737133 0.02948564] | VA-MSE [λ,H,L]= [0.00704298 0.00010547 0.00143589]\n",
      "Epoch  500 | train_loss ~ 2.0632e-04 | VA-MAE [λ,H,L]= [0.05236634 0.00600959 0.04194733] | VA-MSE [λ,H,L]= [9.75995927e-03 5.61886677e-05 2.94035214e-03]\n",
      "Epoch  600 | train_loss ~ 7.1047e-04 | VA-MAE [λ,H,L]= [0.0448761  0.00924852 0.03733893] | VA-MSE [λ,H,L]= [0.00804165 0.00014409 0.00288301]\n",
      "Epoch  700 | train_loss ~ 5.9704e-05 | VA-MAE [λ,H,L]= [0.04694271 0.00662081 0.03545275] | VA-MSE [λ,H,L]= [5.98695430e-03 9.27465639e-05 2.37787340e-03]\n",
      "Epoch  800 | train_loss ~ 1.2930e-05 | VA-MAE [λ,H,L]= [0.03673979 0.00737622 0.03597512] | VA-MSE [λ,H,L]= [4.29410828e-03 9.09866659e-05 2.48281607e-03]\n",
      "Epoch  900 | train_loss ~ 1.0209e-04 | VA-MAE [λ,H,L]= [0.05298577 0.00631082 0.03578375] | VA-MSE [λ,H,L]= [8.00560814e-03 6.88541649e-05 1.96488915e-03]\n",
      "Epoch 1000 | train_loss ~ 1.8894e-05 | VA-MAE [λ,H,L]= [0.03715563 0.0076804  0.03459046] | VA-MSE [λ,H,L]= [5.09354198e-03 9.17082825e-05 2.13690462e-03]\n",
      "Epoch 1100 | train_loss ~ 8.8625e-06 | VA-MAE [λ,H,L]= [0.04100704 0.00617989 0.03302406] | VA-MSE [λ,H,L]= [5.73410248e-03 5.47413384e-05 2.01076770e-03]\n",
      "Epoch 1200 | train_loss ~ 1.4970e-05 | VA-MAE [λ,H,L]= [0.04373174 0.00596032 0.03474711] | VA-MSE [λ,H,L]= [6.21329585e-03 4.54814769e-05 2.00550445e-03]\n",
      "Epoch 1300 | train_loss ~ 6.2659e-06 | VA-MAE [λ,H,L]= [0.0420197  0.00581549 0.03192131] | VA-MSE [λ,H,L]= [5.68626858e-03 4.39733011e-05 1.84603164e-03]\n",
      "Epoch 1400 | train_loss ~ 6.1796e-06 | VA-MAE [λ,H,L]= [0.03916082 0.00546277 0.03007881] | VA-MSE [λ,H,L]= [5.44871629e-03 4.13229800e-05 1.70494324e-03]\n",
      "Epoch 1500 | train_loss ~ 4.1064e-06 | VA-MAE [λ,H,L]= [0.04009034 0.00517241 0.03352661] | VA-MSE [λ,H,L]= [5.22495614e-03 4.19100918e-05 2.27323095e-03]\n",
      "Epoch 1600 | train_loss ~ 7.3777e-05 | VA-MAE [λ,H,L]= [0.03753566 0.00473897 0.02923625] | VA-MSE [λ,H,L]= [5.02423257e-03 2.80518793e-05 1.86361898e-03]\n",
      "Epoch 1700 | train_loss ~ 1.2104e-06 | VA-MAE [λ,H,L]= [0.03575451 0.00468012 0.0290821 ] | VA-MSE [λ,H,L]= [5.10438384e-03 3.24639165e-05 1.95824670e-03]\n",
      "Epoch 1800 | train_loss ~ 1.4004e-06 | VA-MAE [λ,H,L]= [0.03750223 0.00525885 0.03245047] | VA-MSE [λ,H,L]= [4.64988155e-03 3.63010031e-05 2.22258730e-03]\n",
      "Epoch 1900 | train_loss ~ 1.2898e-06 | VA-MAE [λ,H,L]= [0.03726466 0.00513469 0.03188694] | VA-MSE [λ,H,L]= [4.62919596e-03 3.37334557e-05 2.14808880e-03]\n",
      "Epoch 2000 | train_loss ~ 7.8192e-06 | VA-MAE [λ,H,L]= [0.03578281 0.00429082 0.02693051] | VA-MSE [λ,H,L]= [4.07820554e-03 2.53296829e-05 1.55094376e-03]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 6\n",
    "LR = 1e-3\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "ds_tr = XYMDataset(Xn_train, Yn_train, Mn_train)\n",
    "ds_va = XYMDataset(Xn_val, Yn_val, Mn_val)\n",
    "ds_te = XYMDataset(Xn_test, Yn_test, Mn_test)\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "dl_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "dl_te = DataLoader(ds_te, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "valid_counts = Mn_train.sum(axis=0)  # (3,)\n",
    "w_lam = 1.0 / max(valid_counts[0], 1.0)\n",
    "w_geo = 1.0 / max(valid_counts[1] + valid_counts[2], 1.0)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb, mb in dl_tr:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)  # normalized targets\n",
    "        mb = mb.to(DEVICE)\n",
    "\n",
    "        lam_pred, HL_pred = model(xb)          # (B,1), (B,2)\n",
    "        lam_t = yb[:, [0]]                      # (B,1)\n",
    "        HL_t  = yb[:, 1:3]                      # (B,2)\n",
    "        m_lam = mb[:, [0]]\n",
    "        m_geo = mb[:, 1:3]\n",
    "\n",
    "        loss_lam = masked_mse(lam_pred, lam_t, m_lam)\n",
    "        loss_geo = masked_mse(HL_pred,  HL_t,  m_geo)\n",
    "\n",
    "        loss = w_lam * loss_lam + w_geo * loss_geo\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    if epoch % 100 == 0 or epoch == 1:\n",
    "        mae_va, mse_va = evaluate(dl_va, model, tgt_min, tgt_rng)\n",
    "        print(f\"Epoch {epoch:4d} | train_loss ~ {total_loss/len(ds_tr):.4e} | \"\n",
    "              f\"VA-MAE [λ,H,L]= {mae_va} | VA-MSE [λ,H,L]= {mse_va}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06750ec3",
   "metadata": {},
   "source": [
    "### 4.\n",
    "Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e4c16c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST  MAPE [λ,H,L]: [2.1753852  6.35497911 8.38830774] %\n",
      "TEST  MAE [λ,H,L]: [0.00538611 0.00350795 0.03179169]\n",
      "TEST  MSE [λ,H,L]: [4.07779887e-05 1.51146596e-05 1.34482840e-03]\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Final evaluation on TEST\n",
    "# -------------------\n",
    "mae_te, mse_te = evaluate(dl_te, model, tgt_min, tgt_rng)\n",
    "mape_te = mae_te / tgt_rng * 100.0  # in percent\n",
    "print(\"TEST  MAPE [λ,H,L]:\", mape_te, '%')\n",
    "print(\"TEST  MAE [λ,H,L]:\", mae_te)\n",
    "print(\"TEST  MSE [λ,H,L]:\", mse_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
